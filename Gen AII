import fitz  # PyMuPDF
import os
import csv
import json
import uuid
from pathlib import Path
from typing import List, Optional, Union, Dict, Any
from google.genai import types
import google.genai as genai
from langchain.prompts import PromptTemplate
from langchain.output_parsers import PydanticOutputParser, OutputFixingParser
from langchain_core.exceptions import OutputParserException
from pydantic import BaseModel, Field
import pandas as pd

def pdf_to_images(pdf_path, output_dir=None, dpi=150, image_format='png'):
    """Convert each page of a PDF to individual images."""
    pdf_path = Path(pdf_path)
    
    if not pdf_path.exists():
        raise FileNotFoundError(f"PDF file not found: {pdf_path}")
    
    if output_dir is None:
        output_dir = pdf_path.parent
    else:
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)
    
    doc = fitz.open(pdf_path)
    image_paths = []
    
    for page_num in range(len(doc)):
        page = doc.load_page(page_num)
        mat = fitz.Matrix(dpi/72, dpi/72)
        pix = page.get_pixmap(matrix=mat)
        
        output_filename = f"{pdf_path.stem}_page_{page_num + 1:03d}.{image_format}"
        output_path = output_dir / output_filename
        
        pix.save(str(output_path))
        image_paths.append(str(output_path))
        
        print(f"Saved page {page_num + 1} to {output_path}")
        if page_num == 50:  # Limit for large PDFs
            print("Limiting to first 50 pages for large PDFs")
            break
    
    doc.close()
    return image_paths

class DocumentMetadata(BaseModel):
    """Document-level metadata extraction."""
    effective_date: Optional[str] = Field(default=None, description="Effective date found in document")
    hospital_names: Optional[List[str]] = Field(default=None, description="List of hospital names from main title")
    lob_type: Optional[str] = Field(default=None, description="Line of Business type")

class ServiceSection(BaseModel):
    """Individual Place of Service section with its table data."""
    place_of_service: str = Field(description="INPATIENT, OUTPATIENT, INPATIENT CARVE OUT, OUTPATIENT CARVE OUT")
    service_rows: List[Dict[str, str]] = Field(description="List of service rows with service, billing_codes, rates exactly as they appear in table")

class PageExtraction(BaseModel):
    """Complete page extraction including metadata and all sections."""
    has_new_document_section: bool = Field(description="Whether page starts new hospital/LOB section")
    metadata: Optional[DocumentMetadata] = Field(default=None, description="Document metadata if new section")
    service_sections: List[ServiceSection] = Field(description="All Place of Service sections found on this page")
    is_continuation: bool = Field(default=False, description="Whether this continues tables from previous page")

class DocumentContext:
    """Tracks document-level context across pages."""
    def __init__(self):
        self.current_effective_date = None
        self.current_hospital_names = []
        self.current_lob = None
        self.current_place_of_service = None  # Track current place of service
        
    def update_context(self, metadata: DocumentMetadata):
        """Update context with new metadata."""
        if metadata:
            if metadata.effective_date:
                self.current_effective_date = metadata.effective_date
            if metadata.hospital_names:
                self.current_hospital_names = metadata.hospital_names
            if metadata.lob_type:
                self.current_lob = metadata.lob_type
    
    def update_place_of_service(self, place_of_service: str):
        """Update current place of service."""
        self.current_place_of_service = place_of_service

class HospitalRateExtractor:
    """Main extractor class with improved multi-section detection."""
    
    def __init__(self, client, output_dir: str = None):
        self.client = client
        self.output_dir = Path(output_dir) if output_dir else Path.cwd()
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.context = DocumentContext()
        
        # Standard CSV columns
        self.csv_columns = [
            'Hospital_Names', 'LOB', 'Place_of_Service', 'Service', 
            'Billing_Codes', 'Rates', 'Effective_Date'
        ]
        
        # Initialize main CSV file
        self.csv_path = self.output_dir / "extracted_hospital_rates.csv"
        with open(self.csv_path, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.writer(csvfile)
            writer.writerow(self.csv_columns)
    
    def create_multi_section_prompt(self) -> tuple:
        """Create prompt for extracting ALL sections from a page."""
        base_parser = PydanticOutputParser(pydantic_object=PageExtraction)
        
        class GeminiLLM:
            def __init__(self, client):
                self.client = client
                
            def __call__(self, prompt: str) -> str:
                try:
                    response = self.client.models.generate_content(
                        model='gemini-2.0-flash',
                        contents=[prompt]
                    )
                    return response.text
                except Exception as e:
                    return f"Error: {e}"
        
        llm_wrapper = GeminiLLM(self.client)
        parser = OutputFixingParser.from_llm(parser=base_parser, llm=llm_wrapper)
        
        template = """
You are an expert at extracting ALL structured data from hospital rate schedule documents.

CRITICAL CONTEXT RULES:
1. Hospital names should ONLY change when you see a NEW MAIN DOCUMENT HEADER
2. Place of Service should ONLY change when you see a NEW section header
3. Be VERY conservative about detecting "new sections" - most pages are continuations

STEP 1 - DETECT NEW DOCUMENT SECTION (BE VERY STRICT):
Only set has_new_document_section = true if you see:
- A completely NEW MAIN DOCUMENT HEADER in large, centered text
- A clear new hospital name that's different from any previous hospital
- NOT just "Mercy Health" in corner - this is system name, ignore it completely

HOSPITAL NAME RULES:
- ALWAYS IGNORE top right corner (system names like "Mercy Health")
- ONLY extract from NEW main centered headers
- If you don't see a clear NEW main header, do NOT extract hospital names
- Most pages are continuations and should NOT have hospital names extracted

STEP 2 - EXTRACT METADATA (ONLY if genuine NEW MAIN HEADER):
- Hospital Names: Only from clear new main headers
- LOB Type: Only from new main headers  
- Effective Date: Only from new main headers

STEP 3 - PLACE OF SERVICE DETECTION:
Look for NEW section headers like:
- "INPATIENT RATES:" → "INPATIENT"
- "OUTPATIENT RATES:" → "OUTPATIENT"
- "INPATIENT CARVE OUT RATES:" → "INPATIENT CARVE OUT"
- "OUTPATIENT CARVE OUT RATES:" → "OUTPATIENT CARVE OUT"

IMPORTANT: If you see tables without these headers, use the CURRENT place of service context.

STEP 4 - EXTRACT TABLE ROWS:
For each table row:
- service: Exact text from Service column
- billing_codes: Complete text from Billing Codes column
- rates: Complete text from Rates column

CRITICAL RULES:
1. Be VERY conservative about new sections - most pages are continuations
2. NEVER extract "Mercy Health" or similar system names as hospital names
3. ONLY extract hospital names from clear new main document headers
4. If no place of service header visible, assume continuation of current context

{format_instructions}

Analyze this page (remember: be conservative about new sections):
"""
        
        prompt = PromptTemplate(
            template=template,
            input_variables=[],
            partial_variables={"format_instructions": parser.get_format_instructions()}
        )
        
        return prompt, parser
    
    def process_page(self, image_path: str, page_num: int) -> Dict[str, Any]:
        """Process a single page extracting ALL sections."""
        print(f"Processing page {page_num}: {Path(image_path).name}")
        
        try:
            with open(image_path, 'rb') as f:
                image_bytes = f.read()
            
            mime_type = 'image/png' if image_path.lower().endswith('.png') else 'image/jpeg'
            
            # Extract ALL sections using AI with error checking
            prompt, parser = self.create_multi_section_prompt()
            prompt_text = prompt.format()
            
            response = self.client.models.generate_content(
                model='gemini-2.0-flash',
                contents=[
                    types.Part.from_bytes(data=image_bytes, mime_type=mime_type),
                    prompt_text
                ]
            )
            
            print(f"Raw AI response for page {page_num}:")
            print(response.text[:500] + "..." if len(response.text) > 500 else response.text)
            
            parsed_data = parser.parse(response.text.strip())
            
            # Be MUCH more conservative about new document sections
            if parsed_data.has_new_document_section and parsed_data.metadata:
                # ONLY update if we have clearly valid NEW hospital names
                if parsed_data.metadata.hospital_names:
                    valid_hospitals = []
                    for hospital in parsed_data.metadata.hospital_names:
                        hospital_clean = hospital.strip()
                        hospital_lower = hospital_clean.lower()
                        
                        # REJECT system names and corner text
                        system_rejects = [
                            'mercy health', 'memorial health system', 'health system',
                            'reference lab', 'billing', 'admin', 'department'
                        ]
                        
                        is_system_name = any(reject in hospital_lower for reject in system_rejects)
                        
                        # Only accept if it's clearly a hospital facility name
                        if not is_system_name and len(hospital_clean) > 8:
                            # Must have clear hospital indicators
                            hospital_indicators = ['hospital', 'medical center', 'healthcare center']
                            has_hospital_indicator = any(indicator in hospital_lower for indicator in hospital_indicators)
                            
                            if has_hospital_indicator:
                                valid_hospitals.append(hospital_clean)
                    
                    # ONLY update if we found valid hospitals AND they're different from current
                    if valid_hospitals and valid_hospitals != self.context.current_hospital_names:
                        old_metadata = parsed_data.metadata
                        old_metadata.hospital_names = valid_hospitals
                        self.context.update_context(old_metadata)
                        print(f"NEW HOSPITAL SECTION detected - Hospitals: {self.context.current_hospital_names}, LOB: {self.context.current_lob}")
                    else:
                        print(f"Keeping existing hospital context: {self.context.current_hospital_names} (rejected: {parsed_data.metadata.hospital_names})")
                else:
                    print(f"No hospital names extracted, keeping current context: {self.context.current_hospital_names}")
            
            # Update Place of Service context
            for section in parsed_data.service_sections:
                if section.place_of_service:
                    # Update context with new place of service
                    if section.place_of_service != self.context.current_place_of_service:
                        self.context.update_place_of_service(section.place_of_service)
                        print(f"Place of Service changed to: {self.context.current_place_of_service}")
                    break  # Use first section's place of service
            
            # If no explicit place of service found, use current context
            if not parsed_data.service_sections and self.context.current_place_of_service:
                print(f"No sections found, continuing with place of service: {self.context.current_place_of_service}")
            
            # Process ALL service sections with context
            total_rows_added = 0
            sections_processed = []
            
            if not parsed_data.service_sections:
                print(f"  No service sections found on page {page_num}")
            else:
                print(f"  Found {len(parsed_data.service_sections)} service sections")
            
            for i, section in enumerate(parsed_data.service_sections):
                # Use detected place of service or fall back to current context
                effective_place_of_service = section.place_of_service or self.context.current_place_of_service or "UNKNOWN"
                
                print(f"  Processing section {i+1}: {effective_place_of_service}")
                
                if not section.service_rows:
                    print(f"    Section has 0 rows")
                else:
                    print(f"    Found {len(section.service_rows)} rows")
                
                # Log sample rows
                for j, row in enumerate(section.service_rows[:3]):  # Show first 3 rows
                    service_text = row.get('service', 'MISSING')
                    billing_text = row.get('billing_codes', 'MISSING')
                    rates_text = row.get('rates', 'MISSING')
                    
                    print(f"    Row {j+1}: Service='{service_text}', Billing='{billing_text[:50]}...', Rates='{rates_text[:50]}...'")
                
                # Override section's place of service with effective one
                section.place_of_service = effective_place_of_service
                
                rows_added = self.save_section_data(section)
                total_rows_added += rows_added
                sections_processed.append({
                    'place_of_service': effective_place_of_service,
                    'rows_added': rows_added
                })
                print(f"  - {effective_place_of_service}: {rows_added} rows added to CSV")
            
            return {
                'page_num': page_num,
                'has_new_section': parsed_data.has_new_document_section,
                'sections_found': [s['place_of_service'] for s in sections_processed],
                'total_rows_added': total_rows_added,
                'sections_detail': sections_processed,
                'current_context': {
                    'hospitals': self.context.current_hospital_names,
                    'lob': self.context.current_lob,
                    'effective_date': self.context.current_effective_date
                }
            }
            
        except Exception as e:
            print(f"Error processing page {page_num}: {e}")
            return {
                'page_num': page_num,
                'error': str(e),
                'total_rows_added': 0,
                'sections_found': []
            }
    
    def save_section_data(self, section: ServiceSection) -> int:
        """Save extracted section data to CSV exactly as extracted."""
        if not section.service_rows:
            return 0
            
        rows_to_write = []
        
        for row_data in section.service_rows:
            csv_row = [
                '; '.join(self.context.current_hospital_names) if self.context.current_hospital_names else 'N/A',
                self.context.current_lob or 'N/A',
                section.place_of_service,
                row_data.get('service', 'N/A'),
                row_data.get('billing_codes', 'N/A'),
                row_data.get('rates', 'N/A'),
                self.context.current_effective_date or 'N/A'
            ]
            rows_to_write.append(csv_row)
        
        # Append to main CSV
        with open(self.csv_path, 'a', newline='', encoding='utf-8') as csvfile:
            writer = csv.writer(csvfile)
            writer.writerows(rows_to_write)
        
        return len(rows_to_write)
    
    def extract_from_pdf(self, pdf_path: str, dpi: int = 300) -> Dict[str, Any]:
        """Extract all data from PDF with multi-section awareness."""
        print(f"Starting extraction for: {pdf_path}")
        
        # Convert PDF to images
        image_paths = pdf_to_images(pdf_path, self.output_dir, dpi, 'png')
        
        # Process each page
        results = {
            'pdf_path': pdf_path,
            'total_pages': len(image_paths),
            'pages_processed': [],
            'total_rows_extracted': 0,
            'sections_summary': {},
            'csv_file': str(self.csv_path)
        }
        
        for page_num, image_path in enumerate(image_paths, 1):
            page_result = self.process_page(image_path, page_num)
            results['pages_processed'].append(page_result)
            results['total_rows_extracted'] += page_result.get('total_rows_added', 0)
            
            # Track sections found
            for section in page_result.get('sections_found', []):
                if section not in results['sections_summary']:
                    results['sections_summary'][section] = 0
                results['sections_summary'][section] += 1
        
        # Summary
        print(f"\n=== EXTRACTION COMPLETE ===")
        print(f"Total pages processed: {results['total_pages']}")
        print(f"Total rows extracted: {results['total_rows_extracted']}")
        print(f"Sections found: {results['sections_summary']}")
        print(f"Output CSV: {results['csv_file']}")
        
        return results

# Usage example
if __name__ == "__main__":
    # Example usage
    pdf_file = "path/to/your/hospital_rates.pdf"  # Replace with your PDF file path
    
    # Initialize Google AI client
    from google import genai
    client = genai.Client(vertexai=True, project="your-project", location="us-central1")
    
    # Create extractor and process PDF
    extractor = HospitalRateExtractor(client, output_dir="extracted_data")
    results = extractor.extract_from_pdf(pdf_file)
    
    print("Extraction completed successfully!")
