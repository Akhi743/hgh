import fitz  # PyMuPDF
import os
import csv
import json
import uuid
from pathlib import Path
from typing import List, Optional, Union, Dict, Any
from google.genai import types
import google.genai as genai
from langchain.prompts import PromptTemplate
from langchain.output_parsers import PydanticOutputParser, OutputFixingParser
from langchain_core.exceptions import OutputParserException
from pydantic import BaseModel, Field
import pandas as pd

def pdf_to_images(pdf_path, output_dir=None, dpi=150, image_format='png'):
    """Convert each page of a PDF to individual images."""
    pdf_path = Path(pdf_path)
    
    if not pdf_path.exists():
        raise FileNotFoundError(f"PDF file not found: {pdf_path}")
    
    if output_dir is None:
        output_dir = pdf_path.parent
    else:
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)
    
    doc = fitz.open(pdf_path)
    image_paths = []
    
    for page_num in range(len(doc)):
        page = doc.load_page(page_num)
        mat = fitz.Matrix(dpi/72, dpi/72)
        pix = page.get_pixmap(matrix=mat)
        
        output_filename = f"{pdf_path.stem}_page_{page_num + 1:03d}.{image_format}"
        output_path = output_dir / output_filename
        
        pix.save(str(output_path))
        image_paths.append(str(output_path))
        
        print(f"Saved page {page_num + 1} to {output_path}")
        if page_num == 50:  # Limit for large PDFs
            print("Limiting to first 50 pages for large PDFs")
            break
    
    doc.close()
    return image_paths

class DocumentMetadata(BaseModel):
    """Document-level metadata extraction."""
    effective_date: Optional[str] = Field(default=None, description="Effective date found in document")
    hospital_names: Optional[List[str]] = Field(default=None, description="List of hospital names from main title")
    lob_type: Optional[str] = Field(default=None, description="Line of Business type")

class ServiceSection(BaseModel):
    """Individual Place of Service section with its table data."""
    place_of_service: str = Field(description="INPATIENT, OUTPATIENT, INPATIENT CARVE OUT, OUTPATIENT CARVE OUT")
    service_rows: List[Dict[str, str]] = Field(description="List of service rows with service, billing_codes, rates exactly as they appear in table")

class PageExtraction(BaseModel):
    """Complete page extraction including metadata and all sections."""
    has_new_document_section: bool = Field(description="Whether page starts new hospital/LOB section")
    metadata: Optional[DocumentMetadata] = Field(default=None, description="Document metadata if new section")
    service_sections: List[ServiceSection] = Field(description="All Place of Service sections found on this page")
    is_continuation: bool = Field(default=False, description="Whether this continues tables from previous page")

class DocumentContext:
    """Tracks document-level context across pages."""
    def __init__(self):
        self.current_effective_date = None
        self.current_hospital_names = []
        self.current_lob = None
        
    def update_context(self, metadata: DocumentMetadata):
        """Update context with new metadata."""
        if metadata:
            if metadata.effective_date:
                self.current_effective_date = metadata.effective_date
            if metadata.hospital_names:
                self.current_hospital_names = metadata.hospital_names
            if metadata.lob_type:
                self.current_lob = metadata.lob_type

class HospitalRateExtractor:
    """Main extractor class with improved multi-section detection."""
    
    def __init__(self, client, output_dir: str = None):
        self.client = client
        self.output_dir = Path(output_dir) if output_dir else Path.cwd()
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.context = DocumentContext()
        
        # Standard CSV columns - simplified to match table structure
        self.csv_columns = [
            'Hospital_Names', 'LOB', 'Place_of_Service', 'Service', 
            'Billing_Codes', 'Rates', 'Effective_Date'
        ]
        
        # Initialize main CSV file
        self.csv_path = self.output_dir / "extracted_hospital_rates.csv"
        with open(self.csv_path, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.writer(csvfile)
            writer.writerow(self.csv_columns)
    
    def create_multi_section_prompt(self) -> tuple:
        """Create prompt for extracting ALL sections from a page."""
        base_parser = PydanticOutputParser(pydantic_object=PageExtraction)
        
        class GeminiLLM:
            def __init__(self, client):
                self.client = client
                
            def __call__(self, prompt: str) -> str:
                try:
                    response = self.client.models.generate_content(
                        model='gemini-2.0-flash',
                        contents=[prompt]
                    )
                    return response.text
                except Exception as e:
                    return f"Error: {e}"
        
        llm_wrapper = GeminiLLM(self.client)
        parser = OutputFixingParser.from_llm(parser=base_parser, llm=llm_wrapper)
        
        template = """
You are an expert at extracting ALL structured data from hospital rate schedule documents.

CRITICAL EXTRACTION REQUIREMENTS:
1. EXTRACT EVERY SINGLE ROW from every table - NO EXCEPTIONS
2. Count the rows in each table and ensure you extract that exact number
3. If you see 10 rows, extract all 10. If you see 15 rows, extract all 15.

STEP 1 - DETECT NEW DOCUMENT SECTION:
Look for NEW MAIN DOCUMENT HEADER (large centered text) with hospital names like:
- "Sistersville General Hospital"
- "Marietta Memorial TIN 314379509 and Selby General Hospital TIN 314413259"
- "Advocate Condell Medical Center and Advocate Sherman Hospital"

CRITICAL: NEVER extract random text like "MHS REFERENCE LAB" or system names from corners!
ONLY extract hospital names from the MAIN CENTERED DOCUMENT TITLE.

STEP 2 - EXTRACT METADATA (only if NEW MAIN HEADER detected):
- Hospital Names: ONLY from main document title (e.g., "Sistersville General Hospital")
- Effective Date: Date ranges in header (e.g., "6/1/2025 through 5/31/2026")
- LOB Type: Business line from header (COMMERCIAL, MEDICARE, etc.)

STEP 3 - IDENTIFY ALL PLACE OF SERVICE SECTIONS:
Find ALL section headers:
- "INPATIENT RATES:" → "INPATIENT"
- "OUTPATIENT RATES:" → "OUTPATIENT"  
- "INPATIENT CARVE OUT RATES:" → "INPATIENT CARVE OUT"
- "OUTPATIENT CARVE OUT RATES:" → "OUTPATIENT CARVE OUT"

STEP 4 - EXTRACT EVERY SINGLE TABLE ROW:

MANDATORY PROCESS FOR EACH TABLE:
1. Count the total rows in the table visually
2. Extract row-by-row, going through each one systematically
3. For each row extract:
   - service: Exact text from Service column
   - billing_codes: Complete text from Billing Codes column
   - rates: Complete text from Rates column

EXAMPLE - If you see this OUTPATIENT table:
Row 1: Ambulatory Surgery: Default Rate | All surgical procedures not otherwise identified | 85.1% of Billed Charges Rate Applies to Entire Bill
Row 2: Cardiac Catheterization Procedures | HCPC Code: C7521-C7529... | 85.1% of Billed Charges Rate Applies to Entire Bill
Row 3: Cardiac Catheterization Injections | CPT4 Codes: 93563-93568 | 85.1% of Billed Charges Rate Applies to Entire Bill
Row 4: Cardiac Studies | CPT4 Codes: 0541T, 0542T... | 85.1% of Billed Charges
Row 5: Vascular Diagnostic Studies | CPT4 Codes: 93880-93998 | 85.1% of Billed Charges
Row 6: Emergency Care | Revenue Codes: 450, 451, 452, 459 | 85.1% of Billed Charges Rate Applies to Entire Bill
Row 7: Observation Services | Revenue Codes: 762 | 85.1% of Billed Charges

YOU MUST EXTRACT ALL 7 ROWS - NOT 2 OR 3!

VERIFICATION CHECKLIST:
- Did I count all visible rows?
- Did I extract every service name I can see?
- Did I get all the billing codes for each service?
- Did I capture all rate information?

CRITICAL: If a table has 15 visible rows, your extraction MUST have 15 rows. NO SHORTCUTS!

{format_instructions}

Now extract EVERY row from EVERY table on this page:
"""
        
        prompt = PromptTemplate(
            template=template,
            input_variables=[],
            partial_variables={"format_instructions": parser.get_format_instructions()}
        )
        
        return prompt, parser
    
    def process_page(self, image_path: str, page_num: int) -> Dict[str, Any]:
        """Process a single page extracting ALL sections."""
        print(f"Processing page {page_num}: {Path(image_path).name}")
        
        try:
            with open(image_path, 'rb') as f:
                image_bytes = f.read()
            
            mime_type = 'image/png' if image_path.lower().endswith('.png') else 'image/jpeg'
            
            # Extract ALL sections using AI with error checking
            prompt, parser = self.create_multi_section_prompt()
            prompt_text = prompt.format()
            
            response = self.client.models.generate_content(
                model='gemini-2.0-flash',
                contents=[
                    types.Part.from_bytes(data=image_bytes, mime_type=mime_type),
                    prompt_text
                ]
            )
            
            print(f"Raw AI response for page {page_num}:")
            print(response.text[:500] + "..." if len(response.text) > 500 else response.text)
            
            parsed_data = parser.parse(response.text.strip())
            
            # Update context ONLY if new document section with valid hospital names
            if parsed_data.has_new_document_section and parsed_data.metadata:
                # Validate hospital names - reject system names and random text
                if parsed_data.metadata.hospital_names:
                    valid_hospitals = []
                    for hospital in parsed_data.metadata.hospital_names:
                        # Filter out system names and random text
                        hospital_lower = hospital.lower()
                        if not any(invalid_word in hospital_lower for invalid_word in 
                                 ['health system', 'health', 'memorial health system', 'mercy health', 
                                  'mhs reference lab', 'reference lab', 'lab']):
                            # Also check it contains "hospital" or recognizable hospital terms
                            if any(valid_word in hospital_lower for valid_word in 
                                 ['hospital', 'medical center', 'general', 'memorial', 'regional']):
                                valid_hospitals.append(hospital)
                    
                    if valid_hospitals:
                        # Only update if we have valid hospital names
                        old_metadata = parsed_data.metadata
                        old_metadata.hospital_names = valid_hospitals
                        self.context.update_context(old_metadata)
                        print(f"New section detected - Hospitals: {self.context.current_hospital_names}, LOB: {self.context.current_lob}")
                    else:
                        print(f"Ignoring invalid hospital extraction '{parsed_data.metadata.hospital_names}', keeping current context: {self.context.current_hospital_names}")
                else:
                    # Update other metadata but keep existing hospital names
                    if parsed_data.metadata.lob_type:
                        self.context.current_lob = parsed_data.metadata.lob_type
                    if parsed_data.metadata.effective_date:
                        self.context.current_effective_date = parsed_data.metadata.effective_date
            
            # Process ALL service sections with detailed logging
            total_rows_added = 0
            sections_processed = []
            
            if not parsed_data.service_sections:
                print(f"  CRITICAL ERROR: No service sections found on page {page_num}")
                print(f"  This indicates the AI failed to extract the table data!")
            else:
                print(f"  Found {len(parsed_data.service_sections)} service sections")
            
            for i, section in enumerate(parsed_data.service_sections):
                print(f"  Processing section {i+1}: {section.place_of_service}")
                
                if not section.service_rows:
                    print(f"    CRITICAL ERROR: Section has 0 rows - this is likely wrong!")
                else:
                    print(f"    Found {len(section.service_rows)} rows")
                
                # Log ALL rows for verification
                for j, row in enumerate(section.service_rows):
                    service_text = row.get('service', 'MISSING')
                    billing_text = row.get('billing_codes', 'MISSING')
                    rates_text = row.get('rates', 'MISSING')
                    
                    print(f"    Row {j+1}:")
                    print(f"      Service: '{service_text}'")
                    print(f"      Billing: '{billing_text[:100]}{'...' if len(billing_text) > 100 else ''}'")
                    print(f"      Rates: '{rates_text}'")
                
                rows_added = self.save_section_data(section)
                total_rows_added += rows_added
                sections_processed.append({
                    'place_of_service': section.place_of_service,
                    'rows_added': rows_added
                })
                print(f"  - {section.place_of_service}: {rows_added} rows added to CSV")
            
            return {
                'page_num': page_num,
                'has_new_section': parsed_data.has_new_document_section,
                'sections_found': [s['place_of_service'] for s in sections_processed],
                'total_rows_added': total_rows_added,
                'sections_detail': sections_processed,
                'current_context': {
                    'hospitals': self.context.current_hospital_names,
                    'lob': self.context.current_lob,
                    'effective_date': self.context.current_effective_date
                }
            }
            
        except Exception as e:
            print(f"Error processing page {page_num}: {e}")
            return {
                'page_num': page_num,
                'error': str(e),
                'total_rows_added': 0,
                'sections_found': []
            }
    
    def save_section_data(self, section: ServiceSection) -> int:
        """Save extracted section data to CSV exactly as extracted."""
        if not section.service_rows:
            return 0
            
        rows_to_write = []
        
        for row_data in section.service_rows:
            csv_row = [
                '; '.join(self.context.current_hospital_names) if self.context.current_hospital_names else 'N/A',
                self.context.current_lob or 'N/A',
                section.place_of_service,
                row_data.get('service', 'N/A'),
                row_data.get('billing_codes', 'N/A'),
                row_data.get('rates', 'N/A'),
                self.context.current_effective_date or 'N/A'
            ]
            rows_to_write.append(csv_row)
        
        # Append to main CSV
        with open(self.csv_path, 'a', newline='', encoding='utf-8') as csvfile:
            writer = csv.writer(csvfile)
            writer.writerows(rows_to_write)
        
        return len(rows_to_write)
    
    def extract_from_pdf(self, pdf_path: str, dpi: int = 300) -> Dict[str, Any]:
        """Extract all data from PDF with multi-section awareness."""
        print(f"Starting extraction for: {pdf_path}")
        
        # Convert PDF to images
        image_paths = pdf_to_images(pdf_path, self.output_dir, dpi, 'png')
        
        # Process each page
        results = {
            'pdf_path': pdf_path,
            'total_pages': len(image_paths),
            'pages_processed': [],
            'total_rows_extracted': 0,
            'sections_summary': {},
            'csv_file': str(self.csv_path)
        }
        
        for page_num, image_path in enumerate(image_paths, 1):
            page_result = self.process_page(image_path, page_num)
            results['pages_processed'].append(page_result)
            results['total_rows_extracted'] += page_result.get('total_rows_added', 0)
            
            # Track sections found
            for section in page_result.get('sections_found', []):
                if section not in results['sections_summary']:
                    results['sections_summary'][section] = 0
                results['sections_summary'][section] += 1
        
        # Summary
        print(f"\n=== EXTRACTION COMPLETE ===")
        print(f"Total pages processed: {results['total_pages']}")
        print(f"Total rows extracted: {results['total_rows_extracted']}")
        print(f"Sections found: {results['sections_summary']}")
        print(f"Output CSV: {results['csv_file']}")
        
        return results

# Usage
if __name__ == "__main__":
    pdf_file = "path/to/your/hospital_rates.pdf"
    
    # Initialize Google AI client
    from google import genai
    client = genai.Client(vertexai=True, project="your-project", location="us-central1")
    
    # Create extractor and process PDF
    extractor = HospitalRateExtractor(client, output_dir="extracted_data")
    results = extractor.extract_from_pdf(pdf_file)
    
    print("Extraction completed successfully!")
