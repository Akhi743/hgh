import fitz  # PyMuPDF
import os
import csv
import json
import uuid
from pathlib import Path
from typing import List, Optional, Union, Dict, Any
from google.genai import types
import google.genai as genai
from langchain.prompts import PromptTemplate
from langchain.output_parsers import PydanticOutputParser, OutputFixingParser
from langchain_core.exceptions import OutputParserException
from pydantic import BaseModel, Field
import pandas as pd

def pdf_to_images(pdf_path, output_dir=None, dpi=150, image_format='png'):
    """Convert each page of a PDF to individual images."""
    pdf_path = Path(pdf_path)
    
    if not pdf_path.exists():
        raise FileNotFoundError(f"PDF file not found: {pdf_path}")
    
    if output_dir is None:
        output_dir = pdf_path.parent
    else:
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)
    
    doc = fitz.open(pdf_path)
    image_paths = []
    
    for page_num in range(len(doc)):
        page = doc.load_page(page_num)
        mat = fitz.Matrix(dpi/72, dpi/72)
        pix = page.get_pixmap(matrix=mat)
        
        output_filename = f"{pdf_path.stem}_page_{page_num + 1:03d}.{image_format}"
        output_path = output_dir / output_filename
        
        pix.save(str(output_path))
        image_paths.append(str(output_path))
        
        print(f"Saved page {page_num + 1} to {output_path}")
        if page_num == 50:  # Limit for large PDFs
            print("Limiting to first 50 pages for large PDFs")
            break
    
    doc.close()
    return image_paths

class DocumentMetadata(BaseModel):
    """Document-level metadata extraction."""
    effective_date: Optional[str] = Field(default=None, description="Effective date found in document")
    hospital_names: Optional[List[str]] = Field(default=None, description="List of hospital names from main title")
    lob_type: Optional[str] = Field(default=None, description="Line of Business type")

class ServiceSection(BaseModel):
    """Individual Place of Service section with its table data."""
    place_of_service: str = Field(description="INPATIENT, OUTPATIENT, INPATIENT CARVE OUT, OUTPATIENT CARVE OUT")
    service_rows: List[Dict[str, str]] = Field(description="List of service rows with service, billing_code_type, billing_codes, rate_amount, negotiated_type, additional_info")

class PageExtraction(BaseModel):
    """Complete page extraction including metadata and all sections."""
    has_new_document_section: bool = Field(description="Whether page starts new hospital/LOB section")
    metadata: Optional[DocumentMetadata] = Field(default=None, description="Document metadata if new section")
    service_sections: List[ServiceSection] = Field(description="All Place of Service sections found on this page")
    is_continuation: bool = Field(default=False, description="Whether this continues tables from previous page")

class DocumentContext:
    """Tracks document-level context across pages."""
    def __init__(self):
        self.current_effective_date = None
        self.current_hospital_names = []
        self.current_lob = None
        
    def update_context(self, metadata: DocumentMetadata):
        """Update context with new metadata."""
        if metadata:
            if metadata.effective_date:
                self.current_effective_date = metadata.effective_date
            if metadata.hospital_names:
                self.current_hospital_names = metadata.hospital_names
            if metadata.lob_type:
                self.current_lob = metadata.lob_type

class HospitalRateExtractor:
    """Main extractor class with improved multi-section detection."""
    
    def __init__(self, client, output_dir: str = None):
        self.client = client
        self.output_dir = Path(output_dir) if output_dir else Path.cwd()
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.context = DocumentContext()
        
        # Standard CSV columns
        self.csv_columns = [
            'Hospital_Names', 'LOB', 'Place_of_Service', 'Service', 
            'Billing_Code_Type', 'Billing_Codes', 'Rate_Amount', 
            'Negotiated_Type', 'Additional_Info', 'Effective_Date'
        ]
        
        # Initialize main CSV file
        self.csv_path = self.output_dir / "extracted_hospital_rates.csv"
        with open(self.csv_path, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.writer(csvfile)
            writer.writerow(self.csv_columns)
    
    def create_multi_section_prompt(self) -> tuple:
        """Create prompt for extracting ALL sections from a page."""
        base_parser = PydanticOutputParser(pydantic_object=PageExtraction)
        
        class GeminiLLM:
            def __init__(self, client):
                self.client = client
                
            def __call__(self, prompt: str) -> str:
                try:
                    response = self.client.models.generate_content(
                        model='gemini-2.0-flash',
                        contents=[prompt]
                    )
                    return response.text
                except Exception as e:
                    return f"Error: {e}"
        
        llm_wrapper = GeminiLLM(self.client)
        parser = OutputFixingParser.from_llm(parser=base_parser, llm=llm_wrapper)
        
        template = """
You are an expert at extracting ALL structured data from hospital rate schedule documents.

CRITICAL: You must extract ALL Place of Service sections on this page, not just one!

STEP 1 - DETECT NEW DOCUMENT SECTION:
Check if this page starts a NEW hospital/LOB combination by looking for:
- NEW MAIN HEADER with hospital names (large title in center, NOT the system name in top corner)
- Example: "Marietta Memorial TIN 314379509 and Selby General Hospital TIN 314413259"
- Example: "Sistersville General Hospital"  
- NEW LOB type in the main header area (COMMERCIAL, MEDICARE, MEDICAID, etc.)

IMPORTANT: IGNORE system names in top corners like "Memorial Health System" - these are NOT hospital names!

STEP 2 - EXTRACT METADATA (only if NEW MAIN HEADER detected):
- Effective Date: Look for date ranges in header area (e.g., "6/1/2025 through 5/31/2026")
- Hospital Names: Extract ONLY from MAIN HEADER/TITLE area, NOT from top corner
  * Examples: "Marietta Memorial", "Selby General Hospital", "Sistersville General Hospital"
  * NEVER use system names like "Memorial Health System", "Mercy Health", etc.
- LOB Type: Extract from main header area (e.g., "COMMERCIAL" → "Commercial")

STEP 3 - IDENTIFY ALL PLACE OF SERVICE SECTIONS:
Look for ALL section headers on this page:
- "INPATIENT RATES:" → "INPATIENT"
- "INPATIENT CARVE OUT RATES:" → "INPATIENT CARVE OUT"  
- "OUTPATIENT RATES:" → "OUTPATIENT"
- "OUTPATIENT CARVE OUT RATES:" → "OUTPATIENT CARVE OUT"

STEP 4 - EXTRACT ALL TABLES:
For EACH Place of Service section found, extract ALL rows in its table:
- service: Service name/description
- billing_code_type: Code type (Revenue Codes, HCPC Codes, CPT4 Codes, etc.)
- billing_codes: Actual codes/ranges  
- rate_amount: Just the monetary amount or percentage
- negotiated_type: Rate structure (Per Diem, Case Rate, Percentage, etc.)
- additional_info: Special conditions/notes, or "N/A" if none

EXAMPLE EXTRACTION:
If page has:
1. INPATIENT RATES section with 2 rows
2. INPATIENT CARVE OUT RATES section with 3 rows  
3. OUTPATIENT RATES section with 5 rows

You should return 3 ServiceSection objects, each with their respective rows.

CRITICAL RULES:
- Extract EVERY section and EVERY table on the page
- Don't skip sections - if you see "INPATIENT RATES:" and "OUTPATIENT RATES:", extract BOTH
- Each ServiceSection should contain ALL rows from that section's table
- Use "N/A" for missing information

{format_instructions}

Extract ALL sections and tables from this hospital rate schedule page:
"""
        
        prompt = PromptTemplate(
            template=template,
            input_variables=[],
            partial_variables={"format_instructions": parser.get_format_instructions()}
        )
        
        return prompt, parser
    
    def process_page(self, image_path: str, page_num: int) -> Dict[str, Any]:
        """Process a single page extracting ALL sections."""
        print(f"Processing page {page_num}: {Path(image_path).name}")
        
        try:
            with open(image_path, 'rb') as f:
                image_bytes = f.read()
            
            mime_type = 'image/png' if image_path.lower().endswith('.png') else 'image/jpeg'
            
            # Extract ALL sections using AI
            prompt, parser = self.create_multi_section_prompt()
            prompt_text = prompt.format()
            
            response = self.client.models.generate_content(
                model='gemini-2.0-flash',
                contents=[
                    types.Part.from_bytes(data=image_bytes, mime_type=mime_type),
                    prompt_text
                ]
            )
            
            parsed_data = parser.parse(response.text.strip())
            
            # Update context ONLY if new document section with valid hospital names
            if parsed_data.has_new_document_section and parsed_data.metadata:
                # Validate hospital names - reject system names
                if parsed_data.metadata.hospital_names:
                    valid_hospitals = []
                    for hospital in parsed_data.metadata.hospital_names:
                        # Filter out system names
                        if not any(system_word in hospital.lower() for system_word in 
                                 ['health system', 'health', 'memorial health system', 'mercy health']):
                            valid_hospitals.append(hospital)
                    
                    if valid_hospitals:
                        # Only update if we have valid hospital names
                        old_metadata = parsed_data.metadata
                        old_metadata.hospital_names = valid_hospitals
                        self.context.update_context(old_metadata)
                        print(f"New section detected - Hospitals: {self.context.current_hospital_names}, LOB: {self.context.current_lob}")
                    else:
                        print(f"Ignoring system name extraction, keeping current context: {self.context.current_hospital_names}")
                else:
                    # Update other metadata but keep existing hospital names
                    if parsed_data.metadata.lob_type:
                        self.context.current_lob = parsed_data.metadata.lob_type
                    if parsed_data.metadata.effective_date:
                        self.context.current_effective_date = parsed_data.metadata.effective_date
            
            # Process ALL service sections
            total_rows_added = 0
            sections_processed = []
            
            for section in parsed_data.service_sections:
                rows_added = self.save_section_data(section)
                total_rows_added += rows_added
                sections_processed.append({
                    'place_of_service': section.place_of_service,
                    'rows_added': rows_added
                })
                print(f"  - {section.place_of_service}: {rows_added} rows")
            
            return {
                'page_num': page_num,
                'has_new_section': parsed_data.has_new_document_section,
                'sections_found': [s['place_of_service'] for s in sections_processed],
                'total_rows_added': total_rows_added,
                'sections_detail': sections_processed,
                'current_context': {
                    'hospitals': self.context.current_hospital_names,
                    'lob': self.context.current_lob,
                    'effective_date': self.context.current_effective_date
                }
            }
            
        except Exception as e:
            print(f"Error processing page {page_num}: {e}")
            return {
                'page_num': page_num,
                'error': str(e),
                'total_rows_added': 0,
                'sections_found': []
            }
    
    def save_section_data(self, section: ServiceSection) -> int:
        """Save extracted section data to CSV."""
        if not section.service_rows:
            return 0
            
        rows_to_write = []
        
        for row_data in section.service_rows:
            csv_row = [
                '; '.join(self.context.current_hospital_names) if self.context.current_hospital_names else 'N/A',
                self.context.current_lob or 'N/A',
                section.place_of_service,
                row_data.get('service', 'N/A'),
                row_data.get('billing_code_type', 'N/A'),
                row_data.get('billing_codes', 'N/A'),
                row_data.get('rate_amount', 'N/A'),
                row_data.get('negotiated_type', 'N/A'),
                row_data.get('additional_info', 'N/A'),
                self.context.current_effective_date or 'N/A'
            ]
            rows_to_write.append(csv_row)
        
        # Append to main CSV
        with open(self.csv_path, 'a', newline='', encoding='utf-8') as csvfile:
            writer = csv.writer(csvfile)
            writer.writerows(rows_to_write)
        
        return len(rows_to_write)
    
    def extract_from_pdf(self, pdf_path: str, dpi: int = 300) -> Dict[str, Any]:
        """Extract all data from PDF with multi-section awareness."""
        print(f"Starting extraction for: {pdf_path}")
        
        # Convert PDF to images
        image_paths = pdf_to_images(pdf_path, self.output_dir, dpi, 'png')
        
        # Process each page
        results = {
            'pdf_path': pdf_path,
            'total_pages': len(image_paths),
            'pages_processed': [],
            'total_rows_extracted': 0,
            'sections_summary': {},
            'csv_file': str(self.csv_path)
        }
        
        for page_num, image_path in enumerate(image_paths, 1):
            page_result = self.process_page(image_path, page_num)
            results['pages_processed'].append(page_result)
            results['total_rows_extracted'] += page_result.get('total_rows_added', 0)
            
            # Track sections found
            for section in page_result.get('sections_found', []):
                if section not in results['sections_summary']:
                    results['sections_summary'][section] = 0
                results['sections_summary'][section] += 1
        
        # Summary
        print(f"\n=== EXTRACTION COMPLETE ===")
        print(f"Total pages processed: {results['total_pages']}")
        print(f"Total rows extracted: {results['total_rows_extracted']}")
        print(f"Sections found: {results['sections_summary']}")
        print(f"Output CSV: {results['csv_file']}")
        
        return results

# Usage
if __name__ == "__main__":
    pdf_file = "path/to/your/hospital_rates.pdf"
    
    # Initialize Google AI client
    from google import genai
    client = genai.Client(vertexai=True, project="your-project", location="us-central1")
    
    # Create extractor and process PDF
    extractor = HospitalRateExtractor(client, output_dir="extracted_data")
    results = extractor.extract_from_pdf(pdf_file)
    
    print("Extraction completed successfully!")
