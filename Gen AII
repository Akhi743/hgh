import fitz
import os
import csv
import json
import logging
from pathlib import Path
from typing import List, Optional, Dict, Tuple
from pydantic import BaseModel, Field
from google.genai import types
import google.genai as genai

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('hospital_extraction.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class TableRow(BaseModel):
    service: str = Field(description="The full service description from the row.")
    billing_codes: str = Field(description="The full, verbatim text of all billing codes in the cell.")
    rate: str = Field(description="The full, verbatim text of the rate, including all conditions.")

class Section(BaseModel):
    # Only extract if this is a NEW section header
    place_of_service_found: Optional[str] = Field(default=None, description="Place of service if NEW section header found on this page.")
    plan_type_found: Optional[str] = Field(default=None, description="Plan type if found under NEW section header.")
    
    # Always extract table rows
    table_rows: List[TableRow] = Field(description="A list of all table rows extracted from this section.")

class PageExtraction(BaseModel):
    # Only extract if found on this page
    system_name_found: Optional[str] = Field(default=None, description="System name if found on THIS page only.")
    effective_date_found: Optional[str] = Field(default=None, description="Effective date if found on THIS page only.")
    hospital_names_found: Optional[str] = Field(default=None, description="Hospital names if found on THIS page only.")
    line_of_business_found: Optional[str] = Field(default=None, description="Line of Business if found on THIS page only.")
    
    # Always extract sections
    sections: List[Section] = Field(description="A list of all data sections found on this page.")

def pdf_to_images(pdf_path: str, output_dir: str = None, dpi: int = 200) -> List[Path]:
    """Convert PDF pages to images"""
    pdf_path = Path(pdf_path)
    if not pdf_path.exists():
        raise FileNotFoundError(f"PDF file not found: {pdf_path}")
    
    if output_dir is None:
        output_dir = pdf_path.parent / f"{pdf_path.stem}_images"
    else:
        output_dir = Path(output_dir)
    
    output_dir.mkdir(parents=True, exist_ok=True)
    image_paths = []
    
    try:
        doc = fitz.open(str(pdf_path))
        logger.info(f"Converting PDF '{pdf_path.name}' ({len(doc)} pages)")
        
        for page_num in range(len(doc)):
            page = doc.load_page(page_num)
            mat = fitz.Matrix(dpi / 72, dpi / 72)
            pix = page.get_pixmap(matrix=mat)
            
            output_path = output_dir / f"{pdf_path.stem}_page_{page_num + 1:03d}.png"
            pix.save(str(output_path))
            image_paths.append(output_path)
            
        doc.close()
        logger.info(f"Successfully converted {len(image_paths)} pages")
        
    except Exception as e:
        logger.error(f"Failed to convert PDF '{pdf_path.name}': {e}")
        raise
    
    return image_paths

class HierarchicalStateManager:
    """Manages hierarchical context following top-to-bottom, store-and-reuse approach"""
    
    def __init__(self):
        self.columns = [
            "System name", "Effective date", "Hospital Name/Names", 
            "Line of Business", "Place of service", "Plan type", 
            "Service", "Billing codes", "Rate"
        ]
        self.reset_document_state()
    
    def reset_document_state(self):
        """Reset state for new document"""
        # Document-level (stored once for entire PDF)
        self.system_name = "N/A"
        self.effective_date = "N/A"
        
        # Header-level (sticky until new header)
        self.current_hospitals = "N/A"
        self.current_lob = "N/A"
        
        # Sub-header-level (sticky until new sub-header)
        self.current_place_of_service = "N/A"
        self.current_plan_type = "N/A"
        
        # CSV management
        self.csv_file = None
        self.csv_writer = None
        self.csv_path = None
        
        logger.info("Reset document state")
    
    def start_csv(self, output_path: Path):
        """Start new CSV file"""
        self.csv_path = output_path
        self.csv_file = open(self.csv_path, 'w', newline='', encoding='utf-8')
        self.csv_writer = csv.writer(self.csv_file)
        self.csv_writer.writerow(self.columns)
        logger.info(f"Started CSV: {self.csv_path}")
    
    def update_from_page(self, extraction: PageExtraction):
        """Update state from page extraction - hierarchical store and reuse"""
        
        # 1. Document-level: Store once for entire PDF
        if extraction.system_name_found:
            if self.system_name == "N/A" or len(extraction.system_name_found) > len(self.system_name):
                self.system_name = extraction.system_name_found
                logger.info(f"Stored system name: '{self.system_name}'")
            
        if extraction.effective_date_found:
            if self.effective_date == "N/A":
                self.effective_date = extraction.effective_date_found
                logger.info(f"Stored effective date: '{self.effective_date}'")
        
        # 2. Header-level: Update when new header appears  
        if extraction.hospital_names_found:
            # ALWAYS update hospital names when found - this indicates a NEW section
            old_hospitals = self.current_hospitals
            self.current_hospitals = extraction.hospital_names_found
            logger.info(f"NEW HEADER DETECTED - Changed hospital names from '{old_hospitals}' to '{self.current_hospitals}'")
            
        if extraction.line_of_business_found:
            # ALWAYS update LOB when found - this indicates a NEW section
            old_lob = self.current_lob
            self.current_lob = extraction.line_of_business_found
            logger.info(f"NEW HEADER DETECTED - Changed LOB from '{old_lob}' to '{self.current_lob}'")
        
        # 3. Sub-header-level: Update when new section appears
        for section in extraction.sections:
            if section.place_of_service_found:
                # Validate it's a real section header, not a column name
                valid_sections = ["INPATIENT RATES", "OUTPATIENT RATES", "INPATIENT CARVE OUT RATES", "OUTPATIENT CARVE OUT RATES"]
                if any(valid in section.place_of_service_found.upper() for valid in valid_sections):
                    old_pos = self.current_place_of_service
                    self.current_place_of_service = section.place_of_service_found
                    logger.info(f"NEW SECTION DETECTED - Changed place of service from '{old_pos}' to '{self.current_place_of_service}'")
                else:
                    logger.warning(f"INVALID place_of_service ignored: '{section.place_of_service_found}' (not a valid section header)")
                
            if section.plan_type_found:
                old_plan = self.current_plan_type
                self.current_plan_type = section.plan_type_found
                logger.info(f"NEW SECTION - Changed plan type from '{old_plan}' to '{self.current_plan_type}'")
    
    def write_rows(self, extraction: PageExtraction) -> int:
        """Write extracted rows processing each section individually"""
        if not self.csv_writer:
            return 0
        
        rows_written = 0
        
        # Process each section separately
        for section_num, section in enumerate(extraction.sections, 1):
            logger.info(f"Processing section {section_num} on this page")
            
            # Update place of service for this section
            section_place_of_service = self.current_place_of_service  # Default to current
            section_plan_type = self.current_plan_type  # Default to current
            
            # Check if this section has new place of service
            if section.place_of_service_found:
                valid_sections = ["INPATIENT RATES", "OUTPATIENT RATES", "INPATIENT CARVE OUT RATES", "OUTPATIENT CARVE OUT RATES"]
                if any(valid in section.place_of_service_found.upper() for valid in valid_sections):
                    # Update the state for this and subsequent sections
                    old_pos = self.current_place_of_service
                    self.current_place_of_service = section.place_of_service_found
                    section_place_of_service = self.current_place_of_service
                    logger.info(f"Section {section_num}: Changed place of service from '{old_pos}' to '{self.current_place_of_service}'")
                else:
                    logger.warning(f"Section {section_num}: Invalid place_of_service ignored: '{section.place_of_service_found}'")
            
            # Check if this section has new plan type
            if section.plan_type_found:
                old_plan = self.current_plan_type
                self.current_plan_type = section.plan_type_found
                section_plan_type = self.current_plan_type
                logger.info(f"Section {section_num}: Changed plan type from '{old_plan}' to '{self.current_plan_type}'")
            
            # Write all rows for this section
            section_rows = 0
            for row in section.table_rows:
                csv_row = [
                    self.system_name,                    # Stored once for PDF
                    self.effective_date,                 # Stored once for PDF
                    self.current_hospitals,              # Sticky until new header
                    self.current_lob,                   # Sticky until new header
                    section_place_of_service,           # Current section's place of service
                    section_plan_type,                  # Current section's plan type
                    row.service,                        # From current row
                    row.billing_codes,                  # From current row
                    row.rate                            # From current row
                ]
                self.csv_writer.writerow(csv_row)
                section_rows += 1
                rows_written += 1
            
            logger.info(f"Section {section_num}: Wrote {section_rows} rows with place_of_service='{section_place_of_service}'")
        
        if self.csv_file:
            self.csv_file.flush()
        
        logger.info(f"Total rows written from this page: {rows_written}")
        return rows_written
    
    def get_current_state(self):
        """Get current state for debugging"""
        return {
            'system_name': self.system_name,
            'effective_date': self.effective_date,
            'hospitals': self.current_hospitals,
            'lob': self.current_lob,
            'place_of_service': self.current_place_of_service,
            'plan_type': self.current_plan_type
        }
    
    def close_csv(self):
        """Close CSV file"""
        if self.csv_file:
            self.csv_file.close()
            self.csv_file = None
            self.csv_writer = None

class PDFExtractor:
    """PDF extractor using hierarchical store-and-reuse approach"""
    
    def __init__(self, client, output_dir: str = "extraction_output"):
        self.client = client
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.state_manager = HierarchicalStateManager()
    
    def get_extraction_prompt(self) -> str:
        """Generate truly generic extraction prompt for any hospital system"""
        json_schema = json.dumps(PageExtraction.model_json_schema(), indent=2)
        
        return f"""
You are an automated data extraction expert specializing in hospital rate schedules. Your task is to analyze the header of the provided document image and extract the following four key pieces of information.

**1. system_name_found**
* **What it is:** The name of the parent health system or corporation.
* **Where to look:** Typically found in the top-right corner of the page.
* **Examples:** "Advocate Health And Hospital Corporation", "Mercy Health (Ohio)", "Memorial Health System", "Henry Ford Health System".

**2. hospital_names_found**
* **What it is:** The specific name(s) of the hospital(s) covered by the rate schedule. This can be a single hospital or a list of several.
* **Where to look:** Usually located in the center of the header, often in a large font.
* **CRITICAL RULE:** If you see a Taxpayer Identification Number (TIN) next to a name, **extract the name only** and discard the TIN.
* **Examples:**
   * "Mercy Health Youngstown Hospital"
   * "Mercy Tiffin Hospital"
   * "Cleveland Clinic Foundation"
   * "Marietta Memorial and Selby General Hospital" *(extracted from "Marietta Memorial TIN 314379509 and Selby General Hospital TIN 314413259")*

**3. line_of_business_found**
* **What it is:** The type of insurance plan or rate agreement. This is the most important field for categorizing the document.
* **CRITICAL RULE:** Do NOT extract generic titles like "HOSPITAL SERVICE AND RATE SCHEDULE" or "RATE ADDENDA A-1". The Line of Business specifies the plan type.
* **Keywords to look for:** "Commercial", "Gatekeeper", "Non-Gatekeeper", "Qualified Health Plan", "Medicare", "Medicaid".
* **Examples:**
   * "COMMERCIAL GATEKEEPER AND NON-GATEKEEPER PRODUCTS"
   * "Qualified Health Plan Rates"
   * "COMMERCIAL RATE SCHEDULE"

**4. effective_date_found**
* **What it is:** The date when the rates become effective.
* **Where to look:** Look for the label "Effective Date:". It is almost always in the top-right corner.
* **Examples:** "01/01/2025", "09/01/2024", "06/01/2025".

**5. Place of Service Sections**
For each section, look for:
- place_of_service_found: NEW section titles like:
  * "INPATIENT RATES"
  * "OUTPATIENT RATES"
  * "INPATIENT CARVE OUT RATES"
  * "OUTPATIENT CARVE OUT RATES"
  Extract only if this is a NEW section header.
- plan_type_found: Sub-headers under place_of_service that specify a plan variation.
  * Look for keywords like: "PPO", "HMO", "EPO", "POS", "Point of Service", "Exclusive Provider Organization".
  * Extract only if found under a NEW section header.

**6. Table Data Extraction**
- table_rows: Extract data from any content organized into clear columns and rows, even if visual borders or lines are faint or missing. Look for repeating row structures under headers like "Service", "Billing Codes", and "Rates".
  * DO NOT extract from paragraphs or unstructured lists. The data must be in a grid-like or columnar format.
  * For each valid table row extract:
    * service: Full service description.
    * billing_codes: Complete billing codes.
    * rate: Complete rate text.

**EXTRACTION RULES:**
- Only extract fields that are visible on THIS page
- Use null for fields not found on current page
- Remove TIN numbers but keep hospital names
- Preserve ALL text in table rows exactly as written
- Extract complete facility names and business line descriptions

**JSON Schema:**
{json_schema}
"""
    
    def process_page(self, image_path: Path, page_num: int) -> Tuple[int, bool]:
        """Process single page with systematic methodology and debugging"""
        logger.info(f"=== PROCESSING PAGE {page_num}: {image_path.name} ===")
        
        # Show current state before processing
        current_state = self.state_manager.get_current_state()
        logger.info(f"Current state before processing: {current_state}")
        
        try:
            with open(image_path, 'rb') as f:
                image_bytes = f.read()
            
            mime_type = 'image/png' if image_path.suffix.lower() == '.png' else 'image/jpeg'
            prompt = self.get_extraction_prompt()
            
            logger.info("Sending extraction request to AI...")
            
            # API call with fallback
            try:
                response = self.client.models.generate_content(
                    model='gemini-2.0-flash',
                    contents=[
                        types.Part.from_bytes(data=image_bytes, mime_type=mime_type),
                        prompt
                    ]
                )
            except (AttributeError, TypeError):
                response = self.client.generate_content(
                    contents=[
                        types.Part.from_bytes(data=image_bytes, mime_type=mime_type),
                        prompt
                    ]
                )
            
            logger.info("Received response from AI, parsing...")
            
            # Clean response
            response_text = response.text.strip()
            if response_text.startswith('```json'):
                response_text = response_text.split('```json')[1]
            if response_text.endswith('```'):
                response_text = response_text.rsplit('```', 1)[0]
            response_text = response_text.strip()
            
            # Debug: Log raw response
            logger.info(f"Cleaned AI response: {response_text[:500]}...")
            
            # Parse and validate
            extraction = PageExtraction.model_validate_json(response_text)
            
            # Debug: Log what was extracted
            logger.info(f"Extracted fields:")
            logger.info(f"  - system_name_found: {extraction.system_name_found}")
            logger.info(f"  - effective_date_found: {extraction.effective_date_found}")
            logger.info(f"  - hospital_names_found: {extraction.hospital_names_found}")
            logger.info(f"  - line_of_business_found: {extraction.line_of_business_found}")
            logger.info(f"  - sections found: {len(extraction.sections)}")
            
            # Update hierarchical state
            self.state_manager.update_from_page(extraction)
            
            # Write rows using stored context
            rows_written = self.state_manager.write_rows(extraction)
            
            # Show updated state after processing
            updated_state = self.state_manager.get_current_state()
            logger.info(f"Updated state after processing: {updated_state}")
            logger.info(f"Page {page_num}: {rows_written} rows extracted")
            
            # Validation checks
            if extraction.hospital_names_found:
                logger.info(f"✅ SUCCESS: Hospital name extracted on page {page_num}")
            else:
                logger.warning(f"⚠️  WARNING: No hospital name extracted on page {page_num}")
                
            if extraction.sections:
                logger.info(f"✅ SUCCESS: {len(extraction.sections)} sections found on page {page_num}")
            else:
                logger.warning(f"⚠️  WARNING: No sections found on page {page_num}")
            
            return rows_written, True
            
        except Exception as e:
            logger.error(f"❌ CRITICAL ERROR on page {page_num}: {e}")
            logger.error(f"Exception type: {type(e).__name__}")
            import traceback
            logger.error(f"Full traceback: {traceback.format_exc()}")
            return 0, False
    
    def extract_from_pdf(self, pdf_path: str, dpi: int = 200) -> Dict:
        """Extract data from single PDF using store-and-reuse approach"""
        pdf_path = Path(pdf_path)
        logger.info(f"Starting hierarchical extraction: {pdf_path.name}")
        
        try:
            # Reset state for new PDF
            self.state_manager.reset_document_state()
            
            # Convert to images
            image_output_dir = self.output_dir / pdf_path.stem / "images"
            image_paths = pdf_to_images(str(pdf_path), str(image_output_dir), dpi)
            
            # Setup CSV
            csv_path = self.output_dir / pdf_path.stem / f"{pdf_path.stem}_extracted.csv"
            csv_path.parent.mkdir(parents=True, exist_ok=True)
            self.state_manager.start_csv(csv_path)
            
            # Process pages sequentially (top to bottom)
            total_rows = 0
            successful_pages = 0
            
            logger.info("Processing pages sequentially (top to bottom)...")
            
            for i, image_path in enumerate(image_paths, 1):
                logger.info(f"\n--- PAGE {i} ---")
                rows, success = self.process_page(image_path, i)
                total_rows += rows
                if success:
                    successful_pages += 1
            
            # Final state
            final_state = self.state_manager.get_current_state()
            
            results = {
                'pdf_name': pdf_path.name,
                'total_pages': len(image_paths),
                'successful_pages': successful_pages,
                'total_rows': total_rows,
                'csv_path': str(csv_path),
                'final_state': final_state,
                'success_rate': f"{successful_pages}/{len(image_paths)}"
            }
            
            logger.info(f"\nExtraction complete: {pdf_path.name}")
            logger.info(f"Final state: {final_state}")
            logger.info(f"Pages: {successful_pages}/{len(image_paths)} successful")
            logger.info(f"Total rows: {total_rows}")
            logger.info(f"CSV saved: {csv_path}")
            
            return results
            
        except Exception as e:
            logger.error(f"Failed to extract {pdf_path.name}: {e}")
            raise
            
        finally:
            self.state_manager.close_csv()

def create_client():
    """Create client with your setup"""
    try:
        client = genai.Client(vertexai=True, project="anbc-hcb-dev", location="us-central1")
        logger.info("Created Vertex AI client")
        return client
    except Exception as e:
        logger.error(f"Failed to create client: {e}")
        raise

if __name__ == "__main__":
    # Test single PDF with hierarchical approach
    pdf_file = r"path/to/your/test.pdf"  # Change this to your test PDF
    
    try:
        # Create client
        client = create_client()
        
        # Create extractor
        extractor = PDFExtractor(client=client, output_dir="hierarchical_extraction")
        
        # Extract using store-and-reuse approach
        results = extractor.extract_from_pdf(pdf_file, dpi=200)
        
        # Print results
        print("\n" + "="*60)
        print("HIERARCHICAL EXTRACTION RESULTS")
        print("="*60)
        print(f"PDF: {results['pdf_name']}")
        print(f"Pages processed: {results['success_rate']}")
        print(f"Total rows: {results['total_rows']}")
        print(f"Final state: {results['final_state']}")
        print(f"CSV output: {results['csv_path']}")
        print("="*60)
        
    except Exception as e:
        logger.critical(f"Extraction failed: {e}")
        print(f"Error: {e}")
        print("Check hospital_extraction.log for details")
