import fitz  # PyMuPDF
import os
import csv
import json
import uuid
from pathlib import Path
from typing import List, Optional, Union, Dict, Any
from google.genai import types
import google.genai as genai
from langchain.prompts import PromptTemplate
from langchain.output_parsers import PydanticOutputParser, OutputFixingParser
from langchain_core.exceptions import OutputParserException
from pydantic import BaseModel, Field
import pandas as pd

def pdf_to_images(pdf_path, output_dir=None, dpi=150, image_format='png'):
    """Convert each page of a PDF to individual images."""
    pdf_path = Path(pdf_path)
    
    if not pdf_path.exists():
        raise FileNotFoundError(f"PDF file not found: {pdf_path}")
    
    if output_dir is None:
        output_dir = pdf_path.parent
    else:
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)
    
    doc = fitz.open(pdf_path)
    image_paths = []
    
    for page_num in range(len(doc)):
        page = doc.load_page(page_num)
        mat = fitz.Matrix(dpi/72, dpi/72)
        pix = page.get_pixmap(matrix=mat)
        
        output_filename = f"{pdf_path.stem}_page_{page_num + 1:03d}.{image_format}"
        output_path = output_dir / output_filename
        
        pix.save(str(output_path))
        image_paths.append(str(output_path))
        
        print(f"Saved page {page_num + 1} to {output_path}")
        if page_num == 50:  # Limit for large PDFs
            print("Limiting to first 50 pages for large PDFs")
            break
    
    doc.close()
    return image_paths

class DocumentMetadata(BaseModel):
    """Document-level metadata extraction."""
    effective_date: Optional[str] = Field(default=None, description="Effective date found in top corner")
    hospital_names: Optional[List[str]] = Field(default=None, description="List of hospital names from main title")
    lob_type: Optional[str] = Field(default=None, description="Line of Business type")

class PageStructure(BaseModel):
    """Page structure detection and metadata."""
    has_new_section: bool = Field(description="Whether page contains a new hospital/LOB section")
    metadata: Optional[DocumentMetadata] = Field(default=None, description="Document metadata if new section")
    place_of_service: Optional[str] = Field(default=None, description="INPATIENT, OUTPATIENT, etc.")
    has_table: bool = Field(description="Whether page contains tabular data")
    is_continuation: bool = Field(default=False, description="Whether this continues previous table")

class TableRowData(BaseModel):
    """Individual table row data."""
    service: str = Field(description="Service name/description")
    billing_code_type: str = Field(description="Type of billing code (DRG, Revenue Codes, etc.)")
    billing_codes: str = Field(description="The actual codes/ranges")
    rate_amount: str = Field(description="Monetary amount or percentage")
    negotiated_type: str = Field(description="Rate structure (Per Diem, Case Rate, etc.)")
    additional_info: str = Field(description="Special conditions or notes, 'N/A' if none")

class TableData(BaseModel):
    """Complete table extraction."""
    page_structure: PageStructure = Field(description="Page structure information")
    table_rows: Optional[List[TableRowData]] = Field(default=None, description="Extracted table rows")

class DocumentContext:
    """Tracks document-level context across pages."""
    def __init__(self):
        self.current_effective_date = None
        self.current_hospital_names = []
        self.current_lob = None
        self.current_place_of_service = None
        
    def update_context(self, metadata: DocumentMetadata, place_of_service: str = None):
        """Update context with new metadata."""
        if metadata:
            if metadata.effective_date:
                self.current_effective_date = metadata.effective_date
            if metadata.hospital_names:
                self.current_hospital_names = metadata.hospital_names
            if metadata.lob_type:
                self.current_lob = metadata.lob_type
        
        if place_of_service:
            self.current_place_of_service = place_of_service

class HospitalRateExtractor:
    """Main extractor class with improved structure detection."""
    
    def __init__(self, client, output_dir: str = None):
        self.client = client
        self.output_dir = Path(output_dir) if output_dir else Path.cwd()
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.context = DocumentContext()
        
        # Standard CSV columns
        self.csv_columns = [
            'Hospital_Names', 'LOB', 'Place_of_Service', 'Service', 
            'Billing_Code_Type', 'Billing_Codes', 'Rate_Amount', 
            'Negotiated_Type', 'Additional_Info', 'Effective_Date'
        ]
        
        # Initialize main CSV file
        self.csv_path = self.output_dir / "extracted_hospital_rates.csv"
        with open(self.csv_path, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.writer(csvfile)
            writer.writerow(self.csv_columns)
    
    def create_extraction_prompt(self) -> tuple:
        """Create prompt for structured extraction."""
        base_parser = PydanticOutputParser(pydantic_object=TableData)
        
        class GeminiLLM:
            def __init__(self, client):
                self.client = client
                
            def __call__(self, prompt: str) -> str:
                try:
                    response = self.client.models.generate_content(
                        model='gemini-2.0-flash',
                        contents=[prompt]
                    )
                    return response.text
                except Exception as e:
                    return f"Error: {e}"
        
        llm_wrapper = GeminiLLM(self.client)
        parser = OutputFixingParser.from_llm(parser=base_parser, llm=llm_wrapper)
        
        template = """
You are an expert at extracting structured data from hospital rate schedule documents.

EXTRACTION STEPS:

1. DETECT PAGE STRUCTURE:
   - Check if this page starts a NEW hospital/LOB section (new main title)
   - Identify the Place of Service (INPATIENT RATES, OUTPATIENT RATES, etc.)
   - Determine if page contains tabular data or is continuation

2. EXTRACT METADATA (only if new section detected):
   - Effective Date: Look for "Effective Date:" in top corner (format: MM/DD/YYYY)
   - Hospital Names: Extract ACTUAL hospital names from main title, NOT system names
     * Examples: "Mercy Springfield and Urbana Hospitals", "Advocate Condell Medical Center"
     * Ignore system names like "Mercy Health", "Memorial Health System"
   - LOB Type: Look for business line indicators
     * "COMMERCIAL" → "Commercial"
     * "MEDICARE" → "Medicare"  
     * "MEDICAID" → "Medicaid"
     * "ACOP COMMERCIAL" → "ACOP Commercial"

3. IDENTIFY PLACE OF SERVICE:
   - Look for section headers like "INPATIENT RATES:", "OUTPATIENT RATES:", etc.
   - Extract: "INPATIENT", "OUTPATIENT", "INPATIENT CARVE OUT", "OUTPATIENT CARVE OUT"

4. EXTRACT TABLE DATA:
   For each row in any table, extract:
   - service: Service name/description
   - billing_code_type: Code type (DRG, Revenue Codes, HCPC Codes, CPT4 Codes, etc.)
   - billing_codes: Actual codes/ranges
   - rate_amount: Just the monetary amount or percentage
   - negotiated_type: Rate structure (Per Diem, Case Rate, Base Rate, Percentage, etc.)
   - additional_info: Special conditions/notes, or "N/A" if none

IMPORTANT RULES:
- Only extract hospital names that are ACTUAL facility names, not health system names
- If no new section header, assume continuation of previous context
- Break down rate information properly (separate amount from type)
- Use "N/A" for missing information

{format_instructions}

Analyze this hospital rate schedule page:
"""
        
        prompt = PromptTemplate(
            template=template,
            input_variables=[],
            partial_variables={"format_instructions": parser.get_format_instructions()}
        )
        
        return prompt, parser
    
    def process_page(self, image_path: str, page_num: int) -> Dict[str, Any]:
        """Process a single page with context awareness."""
        print(f"Processing page {page_num}: {Path(image_path).name}")
        
        try:
            with open(image_path, 'rb') as f:
                image_bytes = f.read()
            
            mime_type = 'image/png' if image_path.lower().endswith('.png') else 'image/jpeg'
            
            # Extract data using AI
            prompt, parser = self.create_extraction_prompt()
            prompt_text = prompt.format()
            
            response = self.client.models.generate_content(
                model='gemini-2.0-flash',
                contents=[
                    types.Part.from_bytes(data=image_bytes, mime_type=mime_type),
                    prompt_text
                ]
            )
            
            parsed_data = parser.parse(response.text.strip())
            
            # Update context based on extraction
            if parsed_data.page_structure.has_new_section and parsed_data.page_structure.metadata:
                self.context.update_context(
                    parsed_data.page_structure.metadata,
                    parsed_data.page_structure.place_of_service
                )
                print(f"New section detected - Hospital: {self.context.current_hospital_names}, LOB: {self.context.current_lob}")
            elif parsed_data.page_structure.place_of_service:
                self.context.current_place_of_service = parsed_data.page_structure.place_of_service
            
            # Process table data if present
            rows_added = 0
            if parsed_data.table_rows:
                rows_added = self.save_table_data(parsed_data.table_rows)
            
            return {
                'page_num': page_num,
                'has_new_section': parsed_data.page_structure.has_new_section,
                'place_of_service': self.context.current_place_of_service,
                'has_table': parsed_data.page_structure.has_table,
                'rows_added': rows_added,
                'current_context': {
                    'hospitals': self.context.current_hospital_names,
                    'lob': self.context.current_lob,
                    'effective_date': self.context.current_effective_date
                }
            }
            
        except Exception as e:
            print(f"Error processing page {page_num}: {e}")
            return {
                'page_num': page_num,
                'error': str(e),
                'has_table': False,
                'rows_added': 0
            }
    
    def save_table_data(self, table_rows: List[TableRowData]) -> int:
        """Save extracted table rows to CSV."""
        rows_to_write = []
        
        for row in table_rows:
            csv_row = [
                '; '.join(self.context.current_hospital_names) if self.context.current_hospital_names else 'N/A',
                self.context.current_lob or 'N/A',
                self.context.current_place_of_service or 'N/A',
                row.service,
                row.billing_code_type,
                row.billing_codes,
                row.rate_amount,
                row.negotiated_type,
                row.additional_info,
                self.context.current_effective_date or 'N/A'
            ]
            rows_to_write.append(csv_row)
        
        # Append to main CSV
        with open(self.csv_path, 'a', newline='', encoding='utf-8') as csvfile:
            writer = csv.writer(csvfile)
            writer.writerows(rows_to_write)
        
        print(f"Added {len(rows_to_write)} rows to CSV")
        return len(rows_to_write)
    
    def extract_from_pdf(self, pdf_path: str, dpi: int = 300) -> Dict[str, Any]:
        """Extract all data from PDF with structured approach."""
        print(f"Starting extraction for: {pdf_path}")
        
        # Convert PDF to images
        image_paths = pdf_to_images(pdf_path, self.output_dir, dpi, 'png')
        
        # Process each page
        results = {
            'pdf_path': pdf_path,
            'total_pages': len(image_paths),
            'pages_processed': [],
            'total_rows_extracted': 0,
            'csv_file': str(self.csv_path)
        }
        
        for page_num, image_path in enumerate(image_paths, 1):
            page_result = self.process_page(image_path, page_num)
            results['pages_processed'].append(page_result)
            results['total_rows_extracted'] += page_result.get('rows_added', 0)
        
        # Summary
        print(f"\n=== EXTRACTION COMPLETE ===")
        print(f"Total pages processed: {results['total_pages']}")
        print(f"Total rows extracted: {results['total_rows_extracted']}")
        print(f"Output CSV: {results['csv_file']}")
        
        return results

# Usage
if __name__ == "__main__":
    pdf_file = "path/to/your/hospital_rates.pdf"
    
    # Initialize Google AI client
    from google import genai
    client = genai.Client(vertexai=True, project="your-project", location="us-central1")
    
    # Create extractor and process PDF
    extractor = HospitalRateExtractor(client, output_dir="extracted_data")
    results = extractor.extract_from_pdf(pdf_file)
    
    print("Extraction completed successfully!")
