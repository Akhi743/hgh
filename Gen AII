import fitz  # PyMuPDF
import os
import csv
import json
import uuid
import re
from pathlib import Path
from typing import List, Optional, Union, Dict, Any
from google.genai import types
import google.genai as genai
from langchain.prompts import PromptTemplate
from langchain.schema import HumanMessage
from langchain.output_parsers import PydanticOutputParser, OutputFixingParser
from langchain_core.exceptions import OutputParserException
from langchain.agents import Tool, AgentExecutor, create_react_agent
from langchain.memory import ConversationBufferMemory
from pydantic import BaseModel, Field
import pandas as pd

def pdf_to_images(pdf_path, output_dir=None, dpi=150, image_format='png'):
    """
    Convert each page of a PDF to individual images.
   
    Args:
        pdf_path (str): Path to the input PDF file
        output_dir (str): Directory to save images (default: same as PDF)
        dpi (int): Resolution for output images (default: 150)
        image_format (str): Output format ('png', 'jpg', 'jpeg')
   
    Returns:
        list: Paths to the created image files
    """
    pdf_path = Path(pdf_path)
   
    if not pdf_path.exists():
        raise FileNotFoundError(f"PDF file not found: {pdf_path}")
   
    if output_dir is None:
        output_dir = pdf_path.parent
    else:
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)
   
    doc = fitz.open(pdf_path)
    image_paths = []
   
    for page_num in range(len(doc)):
        page = doc.load_page(page_num)
       
        # Create transformation matrix for DPI
        mat = fitz.Matrix(dpi/72, dpi/72)
        pix = page.get_pixmap(matrix=mat)
       
        # Generate output filename
        output_filename = f"{pdf_path.stem}_page_{page_num + 1:03d}.{image_format}"
        output_path = output_dir / output_filename
       
        # Save image
        pix.save(str(output_path))
        image_paths.append(str(output_path))
       
        print(f"Saved page {page_num + 1} to {output_path}")
        if page_num == 50:  # Increased limit for larger documents
            print("Limiting to first 50 pages for large PDFs")
            break
   
    doc.close()
    return image_paths

class TableData(BaseModel):
    """
    Enhanced model for multi-page table data extraction.
    """
    has_table: bool = Field(description="Whether a structured data table is present in the image")
    table_type: Optional[str] = Field(default=None, description="Type: 'new', 'continuation', or 'none'")
    table_id: Optional[str] = Field(default=None, description="Unique identifier for this table")
    column_names: Optional[List[str]] = Field(default=None, description="List of column headers/names")
    data: Optional[List[Dict[str, str]]] = Field(default=None, description="List of rows with detailed breakdown")
    table_description: Optional[str] = Field(default=None, description="Brief description of the table content")
    confidence_score: Optional[float] = Field(default=None, description="Confidence in table detection (0-1)")
    is_continuation: bool = Field(default=False, description="Whether this appears to be a continuation")
    continuation_clues: Optional[List[str]] = Field(default=None, description="Visual/textual clues for continuation")
    
    # Enhanced hospital-specific fields
    health_system_name: Optional[str] = Field(default=None, description="Health system name (e.g., Mercy Health, Memorial Health System)")
    hospital_names: Optional[List[str]] = Field(default=None, description="Specific hospital facility names extracted from document")
    effective_date: Optional[str] = Field(default=None, description="Effective date mentioned in the document")
    lob_type: Optional[str] = Field(default=None, description="Line of Business type (Commercial, ACOP Commercial, etc.)")
    service_type: Optional[str] = Field(default=None, description="INPATIENT or OUTPATIENT only")

class HospitalNameExtractor:
    """
    Utility class to extract specific hospital names from health system information.
    """
    
    # Known health system patterns and their typical hospital name patterns
    HEALTH_SYSTEM_PATTERNS = {
        'mercy_health': {
            'system_indicators': ['mercy health', 'mercy'],
            'hospital_patterns': [
                r'mercy\s+([^,]+?)\s+hospital',
                r'mercy\s+([^,]+?)\s+hospitals',
                r'([^,]+?)\s+mercy\s+hospital',
                r'mercy\s+([^,]+?)\s+medical\s+center'
            ]
        },
        'memorial_health': {
            'system_indicators': ['memorial health system'],
            'hospital_patterns': [
                r'([^,]+?)\s+general\s+hospital',
                r'([^,]+?)\s+memorial\s+hospital',
                r'([^,]+?)\s+medical\s+center',
                r'memorial\s+([^,]+?)\s+hospital'
            ]
        },
        'advocate_health': {
            'system_indicators': ['advocate health', 'advocate'],
            'hospital_patterns': [
                r'advocate\s+([^,]+?)\s+medical\s+center',
                r'advocate\s+([^,]+?)\s+hospital',
                r'([^,]+?)\s+advocate\s+hospital'
            ]
        }
    }
    
    @classmethod
    def extract_hospital_names(cls, text: str, health_system: str = None) -> List[str]:
        """
        Extract specific hospital names from text.
        """
        if not text:
            return []
            
        text_lower = text.lower()
        hospital_names = []
        
        # Try to detect health system if not provided
        if not health_system:
            for system_key, system_info in cls.HEALTH_SYSTEM_PATTERNS.items():
                for indicator in system_info['system_indicators']:
                    if indicator in text_lower:
                        health_system = system_key
                        break
                if health_system:
                    break
        
        # Extract hospital names based on detected system
        if health_system and health_system in cls.HEALTH_SYSTEM_PATTERNS:
            patterns = cls.HEALTH_SYSTEM_PATTERNS[health_system]['hospital_patterns']
            for pattern in patterns:
                matches = re.finditer(pattern, text_lower)
                for match in matches:
                    hospital_name = match.group(1).strip()
                    if hospital_name and len(hospital_name) > 2:
                        # Clean up the name
                        hospital_name = cls._clean_hospital_name(hospital_name)
                        if hospital_name not in hospital_names:
                            hospital_names.append(hospital_name)
        
        # Fallback: look for common hospital keywords
        if not hospital_names:
            fallback_patterns = [
                r'([^,\n]+?)\s+hospital(?:s)?(?:\s|$)',
                r'([^,\n]+?)\s+medical\s+center(?:\s|$)',
                r'([^,\n]+?)\s+health\s+center(?:\s|$)'
            ]
            
            for pattern in fallback_patterns:
                matches = re.finditer(pattern, text_lower)
                for match in matches:
                    name = match.group(1).strip()
                    if len(name) > 5 and 'system' not in name:
                        name = cls._clean_hospital_name(name)
                        if name not in hospital_names:
                            hospital_names.append(name)
        
        return hospital_names[:3]  # Limit to top 3 matches
    
    @classmethod
    def _clean_hospital_name(cls, name: str) -> str:
        """Clean and standardize hospital name."""
        # Remove common prefixes/suffixes that aren't part of the actual name
        name = re.sub(r'^(the\s+)', '', name.strip())
        name = re.sub(r'\s+(and|&)\s+', ' and ', name)
        
        # Title case
        name = ' '.join(word.capitalize() for word in name.split())
        
        return name

class TableRegistry:
    """
    Enhanced registry to track active tables across multiple pages with better hospital name handling.
    """
    def __init__(self, output_dir: Path):
        self.active_tables: Dict[str, Dict[str, Any]] = {}
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # Standard output columns for hospital rates
        self.standard_columns = [
            'Health System', 'Hospital Name', 'LOB', 'Place of Service', 'Service Category', 
            'Billing Code Type', 'Billing Code', 'Rate', 'Negotiated Type',
            'Additional Information', 'Effective Date'
        ]
        
        # Track document-level information
        self.document_health_system = None
        self.document_hospital_names = []
        self.document_effective_date = None
       
    def register_table(self, table_id: str, column_names: List[str], description: str, page_num: int, 
                      health_system: str = "N/A", hospital_names: List[str] = None, 
                      lob_type: str = "N/A", service_type: str = "N/A", 
                      effective_date: str = "N/A") -> str:
        """Register a new table and create its CSV file"""
        csv_filename = f"table_{len(self.active_tables) + 1}_{table_id[:8]}.csv"
        csv_path = self.output_dir / csv_filename
        
        # Update document-level information
        if health_system and health_system != "N/A":
            self.document_health_system = health_system
            
        if hospital_names:
            for name in hospital_names:
                if name and name not in self.document_hospital_names:
                    self.document_hospital_names.append(name)
                    
        if effective_date and effective_date != "N/A":
            self.document_effective_date = effective_date
        
        # Use best available hospital name
        best_hospital_name = self._get_best_hospital_name(hospital_names)
       
        self.active_tables[table_id] = {
            'column_names': self.standard_columns,
            'original_columns': column_names,
            'description': description,
            'start_page': page_num,
            'last_page': page_num,
            'data_rows': [],
            'csv_path': str(csv_path),
            'csv_filename': csv_filename,
            'health_system': self.document_health_system or "N/A",
            'hospital_name': best_hospital_name,
            'lob_type': lob_type,
            'service_type': service_type,
            'effective_date': self.document_effective_date or effective_date
        }
       
        # Create CSV with standard headers
        with open(csv_path, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.writer(csvfile)
            writer.writerow(self.standard_columns)
           
        return str(csv_path)
    
    def _get_best_hospital_name(self, provided_names: List[str] = None) -> str:
        """Get the best available hospital name."""
        # Prioritize provided names
        if provided_names:
            return provided_names[0]
        
        # Fall back to document-level names
        if self.document_hospital_names:
            return self.document_hospital_names[0]
        
        return "N/A"
   
    def add_data_to_table(self, table_id: str, data_rows: List[Dict[str, str]], page_num: int):
        """Add data rows to existing table and append to CSV"""
        if table_id in self.active_tables:
            table_info = self.active_tables[table_id]
            table_info['data_rows'].extend(data_rows)
            table_info['last_page'] = page_num
           
            # Convert and append to CSV
            csv_path = table_info['csv_path']
            standardized_rows = self.convert_to_standard_format(data_rows, table_info)
            
            with open(csv_path, 'a', newline='', encoding='utf-8') as csvfile:
                writer = csv.writer(csvfile)
                for row_data in standardized_rows:
                    writer.writerow([row_data.get(col, 'N/A') for col in self.standard_columns])
               
    def convert_to_standard_format(self, data_rows: List[Dict[str, str]], table_info: Dict[str, Any]) -> List[Dict[str, str]]:
        """Convert raw table data to standard format"""
        standardized_rows = []
        
        for row in data_rows:
            # Determine place of service
            place_of_service = "IP" if table_info['service_type'] == "INPATIENT" else "OP"
            
            row_data = {
                'Health System': table_info['health_system'],
                'Hospital Name': table_info['hospital_name'],
                'LOB': table_info['lob_type'],
                'Place of Service': place_of_service,
                'Service Category': row.get('service', 'N/A'),
                'Billing Code Type': row.get('billing_code_type', 'N/A'),
                'Billing Code': row.get('billing_codes', 'N/A'),
                'Rate': row.get('rate_amount', 'N/A'),
                'Negotiated Type': row.get('negotiated_type', 'N/A'),
                'Additional Information': row.get('additional_info', 'N/A'),
                'Effective Date': table_info['effective_date']
            }
            standardized_rows.append(row_data)
        
        return standardized_rows

    def find_similar_table(self, potential_columns: List[str], similarity_threshold: float = 0.6) -> Optional[str]:
        """Find existing table with similar column structure"""
        best_match = None
        best_similarity = 0
       
        for table_id, table_info in self.active_tables.items():
            existing_cols = table_info['original_columns']
            similarity = self._calculate_column_similarity(existing_cols, potential_columns)
           
            if similarity >= similarity_threshold and similarity > best_similarity:
                best_similarity = similarity
                best_match = table_id
               
        return best_match
       
    def _calculate_column_similarity(self, cols1: List[str], cols2: List[str]) -> float:
        """Calculate similarity between two column sets"""
        if not cols1 or not cols2:
            return 0.0
           
        # Normalize column names for comparison
        cols1_norm = [col.lower().strip() for col in cols1]
        cols2_norm = [col.lower().strip() for col in cols2]
       
        # Calculate Jaccard similarity
        set1, set2 = set(cols1_norm), set(cols2_norm)
        intersection = len(set1 & set2)
        union = len(set1 | set2)
       
        return intersection / union if union > 0 else 0.0
       
    def get_table_context(self, table_id: str) -> Dict[str, Any]:
        """Get context information for a table"""
        return self.active_tables.get(table_id, {})
       
    def get_all_tables(self) -> Dict[str, Dict[str, Any]]:
        """Get all registered tables"""
        return self.active_tables

class MultiPageTableExtractor:
    """
    Enhanced main class for extracting tables across multiple pages with improved hospital name detection.
    """
   
    def __init__(self, client, output_dir: str = None):
        self.client = client
        self.output_dir = Path(output_dir) if output_dir else Path.cwd()
        self.table_registry = TableRegistry(self.output_dir)
        self.hospital_extractor = HospitalNameExtractor()
       
    def create_table_detection_prompt(self) -> tuple:
        """Create enhanced prompt for initial table detection and classification"""
        base_parser = PydanticOutputParser(pydantic_object=TableData)
       
        class GeminiLLM:
            def __init__(self, client):
                self.client = client
               
            def __call__(self, prompt: str) -> str:
                try:
                    response = self.client.models.generate_content(
                        model='gemini-2.0-flash',
                        contents=[prompt]
                    )
                    return response.text
                except Exception as e:
                    return f"Error: {e}"
       
        llm_wrapper = GeminiLLM(self.client)
        table_parser = OutputFixingParser.from_llm(parser=base_parser, llm=llm_wrapper)
       
        template = """
You are an expert table detection and classification specialist for hospital rate schedules.

CRITICAL HOSPITAL NAME EXTRACTION RULES:
1. HEALTH SYSTEM vs HOSPITAL NAME:
   - Health System: "Mercy Health", "Memorial Health System", "Advocate Health And Hospital Corporation"
   - Hospital Names: SPECIFIC facility names like "Springfield Hospital", "Urbana Hospital", "Sistersville General Hospital", "Condell Medical Center", "Sherman Hospital"
   
2. EXTRACT SPECIFIC HOSPITAL NAMES:
   - Look for patterns like: "[Location] Hospital", "[Location] Medical Center", "[Location] General Hospital"
   - Examples: "Mercy Springfield and Urbana Hospitals" → hospital_names: ["Springfield Hospital", "Urbana Hospital"]
   - Examples: "Sistersville General Hospital" → hospital_names: ["Sistersville General Hospital"]
   - Examples: "ADVOCATE CONDELL MEDICAL CENTER AND ADVOCATE SHERMAN HOSPITAL" → hospital_names: ["Condell Medical Center", "Sherman Hospital"]
   
3. AVOID SYSTEM-LEVEL NAMES:
   - DO NOT use "Mercy Health", "Memorial Health System", "Advocate Health" as hospital names
   - These are health systems, not individual hospital facilities

DOCUMENT METADATA EXTRACTION:

1. HEALTH SYSTEM IDENTIFICATION:
   - Extract the health system name from document headers (e.g., "Mercy Health", "Memorial Health System")
   
2. HOSPITAL NAME EXTRACTION:
   - Look carefully in document titles/headers for specific hospital facility names
   - Common patterns: "[City] Hospital", "[Name] Medical Center", "[Location] General Hospital"
   - If multiple hospitals mentioned, extract ALL of them into hospital_names list
   
3. EFFECTIVE DATE:
   - Look for "Effective Date:" followed by a date (format: MM/DD/YYYY)
   
4. LINE OF BUSINESS (LOB):
   - Scan headers/titles for LOB indicators:
     * "COMMERCIAL" → lob_type = "Commercial"
     * "MEDICARE" → lob_type = "Medicare" 
     * "MEDICAID" → lob_type = "Medicaid"
     * "ACOP COMMERCIAL" → lob_type = "ACOP Commercial"
     * If NO LOB mentioned → lob_type = "N/A"
   
5. SERVICE TYPE:
   - Look for section headers:
     * "INPATIENT RATES" or "INPATIENT CARVE OUT RATES" → service_type = "INPATIENT"
     * "OUTPATIENT RATES" or "OUTPATIENT CARVE OUT RATES" → service_type = "OUTPATIENT"

TABLE DATA EXTRACTION:
For each row in the table, extract:
- service: The service name/description
- billing_code_type: The type of billing code (DRG, Revenue Codes, HCPC Codes, CPT4 Codes)
- billing_codes: The actual codes/ranges
- rate_amount: Just the monetary amount or percentage
- negotiated_type: The rate structure (Per Diem, Case Rate, Base Rate, Percentage)
- additional_info: Any special conditions or notes (set to "N/A" if none)

RATE PARSING EXAMPLES:
- "$1,800.00 Per Diem" → rate_amount="$1,800.00", negotiated_type="Per Diem", additional_info="N/A"
- "$354,075.00 Case Rate" → rate_amount="$354,075.00", negotiated_type="Case Rate", additional_info="N/A"
- "33% of Billed Charges" → rate_amount="33%", negotiated_type="Percentage", additional_info="N/A"
- "$750.00 Per Diem Paid In Addition to Other Negotiated Rates" → rate_amount="$750.00", negotiated_type="Per Diem", additional_info="Paid In Addition to Other Negotiated Rates"

TABLE TYPE CLASSIFICATION:
- NEW TABLE: Has visible column headers at the top
- CONTINUATION: Has data rows but no headers (continuing from previous page)
- NONE: No structured table present

{format_instructions}

Analyze the image and extract hospital rate information with precise hospital name identification:
"""
       
        prompt = PromptTemplate(
            template=template,
            input_variables=[],
            partial_variables={"format_instructions": table_parser.get_format_instructions()}
        )
       
        return prompt, table_parser
       
    def create_context_aware_prompt(self, context_info: Dict[str, Any]) -> tuple:
        """Create context-aware prompt for table continuation extraction"""
        base_parser = PydanticOutputParser(pydantic_object=TableData)
       
        class GeminiLLM:
            def __init__(self, client):
                self.client = client
               
            def __call__(self, prompt: str) -> str:
                try:
                    response = self.client.models.generate_content(
                        model='gemini-2.0-flash',
                        contents=[prompt]
                    )
                    return response.text
                except Exception as e:
                    return f"Error: {e}"
       
        llm_wrapper = GeminiLLM(self.client)
        table_parser = OutputFixingParser.from_llm(parser=base_parser, llm=llm_wrapper)
       
        expected_columns = context_info.get('original_columns', [])
        table_description = context_info.get('description', 'Table continuation')
       
        template = f"""
You are extracting data from a KNOWN table continuation. This table has been identified across multiple pages.

KNOWN TABLE STRUCTURE:
- Columns: {expected_columns}
- Description: {table_description}

EXTRACTION INSTRUCTIONS:
1. Extract ONLY data rows (no headers)
2. For each row, extract the detailed breakdown:
   - service: The service name/description 
   - billing_code_type: The type of billing code
   - billing_codes: The actual codes/ranges 
   - rate_amount: Just the monetary amount or percentage 
   - negotiated_type: The rate structure
   - additional_info: Any special conditions or notes

3. Use empty string "" for missing/empty fields
4. Preserve exact text including numbers, dates, symbols

IMPORTANT SETTINGS:
- Set has_table: true
- Set is_continuation: true  
- Set table_type: "continuation"

{{format_instructions}}

Extract the table data rows:
"""
       
        prompt = PromptTemplate(
            template=template,
            input_variables=[],
            partial_variables={"format_instructions": table_parser.get_format_instructions()}
        )
       
        return prompt, table_parser
       
    def process_page(self, image_path: str, page_num: int) -> Dict[str, Any]:
        """Process a single page with enhanced hospital name detection"""
        print(f"Processing page {page_num}: {Path(image_path).name}")
       
        try:
            with open(image_path, 'rb') as f:
                image_bytes = f.read()
           
            mime_type = 'image/png' if image_path.lower().endswith('.png') else 'image/jpeg'
           
            # Step 1: Initial table detection
            detection_prompt, detection_parser = self.create_table_detection_prompt()
            detection_text = detection_prompt.format()
           
            response = self.client.models.generate_content(
                model='gemini-2.0-flash',
                contents=[
                    types.Part.from_bytes(data=image_bytes, mime_type=mime_type),
                    detection_text
                ]
            )
           
            parsed_response = detection_parser.parse(response.text.strip())
           
            if not parsed_response.has_table:
                print(f"No table found on page {page_num}")
                return {
                    'page_num': page_num,
                    'has_table': False,
                    'reason': getattr(parsed_response, 'reason', 'No table detected')
                }
           
            # Enhanced hospital name processing
            hospital_names = []
            if parsed_response.hospital_names:
                hospital_names = parsed_response.hospital_names
            elif parsed_response.health_system_name:
                # Try to extract hospital names from the full response text
                hospital_names = self.hospital_extractor.extract_hospital_names(
                    response.text, 
                    parsed_response.health_system_name.lower().replace(' ', '_')
                )
           
            # Step 2: Handle different table types
            if parsed_response.table_type == "new" or (parsed_response.column_names and not parsed_response.is_continuation):
                # New table detected
                table_id = str(uuid.uuid4())
                column_names = parsed_response.column_names
                description = parsed_response.table_description or f"Table starting on page {page_num}"
               
                print(f"New table detected: {description}")
                print(f"Health System: {parsed_response.health_system_name}")
                print(f"Hospital Names: {hospital_names}")
                print(f"Columns: {column_names}")
               
                # Register new table with enhanced metadata
                csv_path = self.table_registry.register_table(
                    table_id, column_names, description, page_num,
                    parsed_response.health_system_name or "N/A",
                    hospital_names,
                    parsed_response.lob_type or "N/A", 
                    parsed_response.service_type or "N/A",
                    parsed_response.effective_date or "N/A"
                )
               
                # Add initial data if present
                if parsed_response.data:
                    self.table_registry.add_data_to_table(table_id, parsed_response.data, page_num)
                    print(f"Added {len(parsed_response.data)} initial rows")
               
                return {
                    'page_num': page_num,
                    'has_table': True,
                    'table_type': 'new',
                    'table_id': table_id,
                    'csv_path': csv_path,
                    'rows_added': len(parsed_response.data) if parsed_response.data else 0,
                    'hospital_names': hospital_names
                }
               
            elif parsed_response.is_continuation or parsed_response.table_type == "continuation":
                # Table continuation detected
                print(f"Table continuation detected on page {page_num}")
               
                # Try to match with existing table
                if parsed_response.column_names:
                    matching_table_id = self.table_registry.find_similar_table(parsed_response.column_names)
                else:
                    # Assume continuation of most recent table
                    matching_table_id = list(self.table_registry.active_tables.keys())[-1] if self.table_registry.active_tables else None
               
                if matching_table_id:
                    context_info = self.table_registry.get_table_context(matching_table_id)
                   
                    # Re-extract with context
                    context_prompt, context_parser = self.create_context_aware_prompt(context_info)
                    context_text = context_prompt.format()
                   
                    context_response = self.client.models.generate_content(
                        model='gemini-2.0-flash',
                        contents=[
                            types.Part.from_bytes(data=image_bytes, mime_type=mime_type),
                            context_text
                        ]
                    )
                   
                    context_parsed = context_parser.parse(context_response.text.strip())
                   
                    if context_parsed.data:
                        self.table_registry.add_data_to_table(matching_table_id, context_parsed.data, page_num)
                        print(f"Added {len(context_parsed.data)} rows to existing table")
                       
                        return {
                            'page_num': page_num,
                            'has_table': True,
                            'table_type': 'continuation',
                            'table_id': matching_table_id,
                            'rows_added': len(context_parsed.data)
                        }
               
                print(f"Could not match continuation to existing table")
                return {
                    'page_num': page_num,
                    'has_table': False,
                    'reason': 'Continuation detected but no matching table found'
                }
           
        except Exception as e:
            print(f"Error processing page {page_num}: {e}")
            return {
                'page_num': page_num,
                'has_table': False,
                'error': str(e)
            }
   
    def extract_tables_from_pdf(self, pdf_path: str, dpi: int = 150, image_format: str = 'png') -> Dict[str, Any]:
        """
        Extract all tables from PDF with enhanced multi-page awareness.
        """
        print(f"Starting enhanced multi-page table extraction for: {pdf_path}")
       
        # Convert PDF to images
        image_paths = pdf_to_images(pdf_path, self.output_dir, dpi, image_format)
       
        # Process each page
        results = {
            'pdf_path': pdf_path,
            'total_pages': len(image_paths),
            'processed_pages': [],
            'tables_found': {},
            'csv_files': [],
            'document_summary': {
                'health_system': None,
                'hospital_names': [],
                'effective_date': None
            }
        }
       
        for page_num, image_path in enumerate(image_paths, 1):
            page_result = self.process_page(image_path, page_num)
            results['processed_pages'].append(page_result)
           
            if page_result.get('table_id'):
                table_id = page_result['table_id']
                if table_id not in results['tables_found']:
                    table_info = self.table_registry.get_table_context(table_id)
                    results['tables_found'][table_id] = {
                        'description': table_info['description'],
                        'columns': table_info['original_columns'],
                        'csv_path': table_info['csv_path'],
                        'health_system': table_info.get('health_system', 'N/A'),
                        'hospital_name': table_info.get('hospital_name', 'N/A'),
                        'lob_type': table_info.get('lob_type', 'N/A'),
                        'service_type': table_info.get('service_type', 'N/A'),
                        'effective_date': table_info.get('effective_date', 'N/A'),
                        'pages': []
                    }
                results['tables_found'][table_id]['pages'].append(page_num)
       
        # Update document summary
        results['document_summary'] = {
            'health_system': self.table_registry.document_health_system,
            'hospital_names': self.table_registry.document_hospital_names,
            'effective_date': self.table_registry.document_effective_date
        }
       
        # Get final CSV files
        for table_info in self.table_registry.get_all_tables().values():
            results['csv_files'].append(table_info['csv_path'])
       
        # Enhanced summary
        total_tables = len(results['tables_found'])
        pages_with_tables = len([p for p in results['processed_pages'] if p.get('has_table')])
        total_rows_extracted = sum(len(table_info['data_rows']) for table_info in self.table_registry.get_all_tables().values())
       
        print(f"\n=== ENHANCED MULTI-PAGE EXTRACTION SUMMARY ===")
        print(f"PDF File: {pdf_path}")
        print(f"Health System: {results['document_summary']['health_system']}")
        print(f"Hospital Names: {', '.join(results['document_summary']['hospital_names']) if results['document_summary']['hospital_names'] else 'N/A'}")
        print(f"Effective Date: {results['document_summary']['effective_date']}")
        print(f"Total pages processed: {results['total_pages']}")
        print(f"Pages with tables: {pages_with_tables}")
        print(f"Unique tables found: {total_tables}")
        print(f"Total rows extracted: {total_rows_extracted}")
        print(f"CSV files created: {len(results['csv_files'])}")
       
        if results['csv_files']:
            print(f"\nCSV Files Created:")
            for csv_file in results['csv_files']:
                print(f"  - {csv_file}")
        
        # Generate summary report
        self._generate_extraction_report(results)
       
        return results
    
    def _generate_extraction_report(self, results: Dict[str, Any]):
        """Generate a detailed extraction report"""
        report_path = self.output_dir / "extraction_report.txt"
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("HOSPITAL RATE SCHEDULE EXTRACTION REPORT\n")
            f.write("=" * 50 + "\n\n")
            
            f.write(f"Source PDF: {results['pdf_path']}\n")
            f.write(f"Health System: {results['document_summary']['health_system']}\n")
            f.write(f"Hospital Names: {', '.join(results['document_summary']['hospital_names']) if results['document_summary']['hospital_names'] else 'N/A'}\n")
            f.write(f"Effective Date: {results['document_summary']['effective_date']}\n")
            f.write(f"Total Pages: {results['total_pages']}\n\n")
            
            f.write("TABLE EXTRACTION DETAILS:\n")
            f.write("-" * 30 + "\n")
            
            for table_id, table_info in results['tables_found'].items():
                f.write(f"\nTable ID: {table_id[:8]}...\n")
                f.write(f"  Description: {table_info['description']}\n")
                f.write(f"  Health System: {table_info['health_system']}\n")
                f.write(f"  Hospital: {table_info['hospital_name']}\n")
                f.write(f"  LOB: {table_info['lob_type']}\n")
                f.write(f"  Service Type: {table_info['service_type']}\n")
                f.write(f"  Pages: {', '.join(map(str, table_info['pages']))}\n")
                f.write(f"  CSV File: {table_info['csv_path']}\n")
            
            f.write(f"\nExtraction completed successfully!\n")
        
        print(f"Detailed report saved to: {report_path}")

    def process_batch_pdfs(self, pdf_directory: str, output_base_dir: str = None) -> Dict[str, Any]:
        """
        Process multiple PDF files in batch.
        """
        pdf_dir = Path(pdf_directory)
        if not pdf_dir.exists():
            raise FileNotFoundError(f"Directory not found: {pdf_directory}")
        
        if output_base_dir is None:
            output_base_dir = pdf_dir / "extracted_tables"
        else:
            output_base_dir = Path(output_base_dir)
        
        pdf_files = list(pdf_dir.glob("*.pdf"))
        if not pdf_files:
            print(f"No PDF files found in {pdf_directory}")
            return {}
        
        batch_results = {
            'total_pdfs': len(pdf_files),
            'processed_pdfs': [],
            'failed_pdfs': [],
            'summary': {
                'total_tables': 0,
                'total_rows': 0,
                'total_csv_files': 0
            }
        }
        
        print(f"Starting batch processing of {len(pdf_files)} PDF files...")
        
        for i, pdf_file in enumerate(pdf_files, 1):
            print(f"\n{'='*60}")
            print(f"Processing PDF {i}/{len(pdf_files)}: {pdf_file.name}")
            print(f"{'='*60}")
            
            try:
                # Create output directory for this PDF
                pdf_output_dir = output_base_dir / pdf_file.stem
                
                # Update extractor output directory
                self.output_dir = pdf_output_dir
                self.table_registry = TableRegistry(pdf_output_dir)
                
                # Process the PDF
                results = self.extract_tables_from_pdf(str(pdf_file))
                
                batch_results['processed_pdfs'].append({
                    'pdf_name': pdf_file.name,
                    'pdf_path': str(pdf_file),
                    'output_dir': str(pdf_output_dir),
                    'results': results
                })
                
                # Update summary
                batch_results['summary']['total_tables'] += len(results['tables_found'])
                batch_results['summary']['total_csv_files'] += len(results['csv_files'])
                
                for table_info in self.table_registry.get_all_tables().values():
                    batch_results['summary']['total_rows'] += len(table_info['data_rows'])
                
            except Exception as e:
                print(f"ERROR processing {pdf_file.name}: {e}")
                batch_results['failed_pdfs'].append({
                    'pdf_name': pdf_file.name,
                    'error': str(e)
                })
        
        # Generate batch summary report
        self._generate_batch_report(batch_results, output_base_dir)
        
        return batch_results
    
    def _generate_batch_report(self, batch_results: Dict[str, Any], output_dir: Path):
        """Generate a comprehensive batch processing report"""
        report_path = output_dir / "batch_extraction_summary.txt"
        output_dir.mkdir(parents=True, exist_ok=True)
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("HOSPITAL RATE SCHEDULE BATCH EXTRACTION SUMMARY\n")
            f.write("=" * 60 + "\n\n")
            
            f.write(f"Total PDFs Processed: {batch_results['total_pdfs']}\n")
            f.write(f"Successfully Processed: {len(batch_results['processed_pdfs'])}\n")
            f.write(f"Failed: {len(batch_results['failed_pdfs'])}\n\n")
            
            f.write("OVERALL STATISTICS:\n")
            f.write("-" * 20 + "\n")
            f.write(f"Total Tables Extracted: {batch_results['summary']['total_tables']}\n")
            f.write(f"Total Rows Extracted: {batch_results['summary']['total_rows']}\n")
            f.write(f"Total CSV Files Created: {batch_results['summary']['total_csv_files']}\n\n")
            
            if batch_results['processed_pdfs']:
                f.write("SUCCESSFULLY PROCESSED FILES:\n")
                f.write("-" * 30 + "\n")
                for pdf_info in batch_results['processed_pdfs']:
                    f.write(f"\n{pdf_info['pdf_name']}:\n")
                    f.write(f"  Health System: {pdf_info['results']['document_summary']['health_system']}\n")
                    f.write(f"  Hospital Names: {', '.join(pdf_info['results']['document_summary']['hospital_names']) if pdf_info['results']['document_summary']['hospital_names'] else 'N/A'}\n")
                    f.write(f"  Tables Found: {len(pdf_info['results']['tables_found'])}\n")
                    f.write(f"  CSV Files: {len(pdf_info['results']['csv_files'])}\n")
                    f.write(f"  Output Directory: {pdf_info['output_dir']}\n")
            
            if batch_results['failed_pdfs']:
                f.write("\nFAILED FILES:\n")
                f.write("-" * 15 + "\n")
                for failed_pdf in batch_results['failed_pdfs']:
                    f.write(f"{failed_pdf['pdf_name']}: {failed_pdf['error']}\n")
        
        print(f"\nBatch processing summary saved to: {report_path}")

# Enhanced usage example
if __name__ == "__main__":
    # Configuration
    pdf_file = r"C:\Users\N873855\Documents\extracted_tables\Mercy_health.pdf"  # Single PDF
    pdf_directory = r"C:\Users\N873855\Documents\pdf_batch"  # Directory for batch processing
    output_directory = "enhanced_extracted_tables"
    
    # Initialize Gemini client
    from google import genai
    client = genai.Client(vertexai=True, project="anbc-hcb-dev", location="us-central1")
    
    # Create extractor instance
    extractor = MultiPageTableExtractor(client, output_dir=output_directory)
    
    print("Enhanced Hospital Rate Extractor Ready!")
    print("Features:")
    print("- Improved hospital name extraction")
    print("- Enhanced health system vs hospital distinction")
    print("- Better LOB and service type detection")
    print("- Standardized CSV output format")
    print("- Batch processing capabilities")
    print("- Detailed extraction reports")
    
    # Example: Single PDF processing
    # results = extractor.extract_tables_from_pdf(pdf_file, dpi=300)
    
    # Example: Batch processing
    # batch_results = extractor.process_batch_pdfs(pdf_directory, output_directory)
