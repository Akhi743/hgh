import fitz
import os
import csv
import json
import logging
from pathlib import Path
from typing import List, Optional, Dict, Tuple
from pydantic import BaseModel, Field
from google.genai import types
import google.genai as genai

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('hospital_extraction.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class TableRow(BaseModel):
    service: str = Field(description="The full service description from the row.")
    billing_codes: str = Field(description="The full, verbatim text of all billing codes in the cell.")
    rate: str = Field(description="The full, verbatim text of the rate, including all conditions.")

class Section(BaseModel):
    # Only extract if this is a NEW section header
    place_of_service_found: Optional[str] = Field(default=None, description="Place of service if NEW section header found on this page.")
    plan_type_found: Optional[str] = Field(default=None, description="Plan type if found under NEW section header.")
    
    # Always extract table rows
    table_rows: List[TableRow] = Field(description="A list of all table rows extracted from this section.")

class PageExtraction(BaseModel):
    # Only extract if found on this page
    system_name_found: Optional[str] = Field(default=None, description="System name if found on THIS page only.")
    effective_date_found: Optional[str] = Field(default=None, description="Effective date if found on THIS page only.")
    hospital_names_found: Optional[str] = Field(default=None, description="Hospital names if found on THIS page only.")
    line_of_business_found: Optional[str] = Field(default=None, description="Line of Business if found on THIS page only.")
    
    # Always extract sections
    sections: List[Section] = Field(description="A list of all data sections found on this page.")

def pdf_to_images(pdf_path: str, output_dir: str = None, dpi: int = 200) -> List[Path]:
    """Convert PDF pages to images"""
    pdf_path = Path(pdf_path)
    if not pdf_path.exists():
        raise FileNotFoundError(f"PDF file not found: {pdf_path}")
    
    if output_dir is None:
        output_dir = pdf_path.parent / f"{pdf_path.stem}_images"
    else:
        output_dir = Path(output_dir)
    
    output_dir.mkdir(parents=True, exist_ok=True)
    image_paths = []
    
    try:
        doc = fitz.open(str(pdf_path))
        logger.info(f"Converting PDF '{pdf_path.name}' ({len(doc)} pages)")
        
        for page_num in range(len(doc)):
            page = doc.load_page(page_num)
            mat = fitz.Matrix(dpi / 72, dpi / 72)
            pix = page.get_pixmap(matrix=mat)
            
            output_path = output_dir / f"{pdf_path.stem}_page_{page_num + 1:03d}.png"
            pix.save(str(output_path))
            image_paths.append(output_path)
            
        doc.close()
        logger.info(f"Successfully converted {len(image_paths)} pages")
        
    except Exception as e:
        logger.error(f"Failed to convert PDF '{pdf_path.name}': {e}")
        raise
    
    return image_paths

class HierarchicalStateManager:
    """Manages hierarchical context following top-to-bottom, store-and-reuse approach"""
    
    def __init__(self):
        self.columns = [
            "System name", "Effective date", "Hospital Name/Names", 
            "Line of Business", "Place of service", "Plan type", 
            "Service", "Billing codes", "Rate"
        ]
        self.reset_document_state()
    
    def reset_document_state(self):
        """Reset state for new document"""
        # Document-level (stored once for entire PDF)
        self.system_name = "N/A"
        self.effective_date = "N/A"
        
        # Header-level (sticky until new header)
        self.current_hospitals = "N/A"
        self.current_lob = "N/A"
        
        # Sub-header-level (sticky until new sub-header)
        self.current_place_of_service = "N/A"
        self.current_plan_type = "N/A"
        
        # CSV management
        self.csv_file = None
        self.csv_writer = None
        self.csv_path = None
        
        logger.info("Reset document state")
    
    def start_csv(self, output_path: Path):
        """Start new CSV file"""
        self.csv_path = output_path
        self.csv_file = open(self.csv_path, 'w', newline='', encoding='utf-8')
        self.csv_writer = csv.writer(self.csv_file)
        self.csv_writer.writerow(self.columns)
        logger.info(f"Started CSV: {self.csv_path}")
    
    def update_from_page(self, extraction: PageExtraction):
        """Update state from page extraction - hierarchical store and reuse"""
        
        # 1. Document-level: Store once for entire PDF
        if extraction.system_name_found:
            if self.system_name == "N/A" or len(extraction.system_name_found) > len(self.system_name):
                self.system_name = extraction.system_name_found
                logger.info(f"Stored system name: '{self.system_name}'")
            
        if extraction.effective_date_found:
            if self.effective_date == "N/A":
                self.effective_date = extraction.effective_date_found
                logger.info(f"Stored effective date: '{self.effective_date}'")
        
        # 2. Header-level: Update when new header appears  
        if extraction.hospital_names_found:
            # ALWAYS update hospital names when found - this indicates a NEW section
            old_hospitals = self.current_hospitals
            self.current_hospitals = extraction.hospital_names_found
            logger.info(f"NEW HEADER DETECTED - Changed hospital names from '{old_hospitals}' to '{self.current_hospitals}'")
            
        if extraction.line_of_business_found:
            # ALWAYS update LOB when found - this indicates a NEW section
            old_lob = self.current_lob
            self.current_lob = extraction.line_of_business_found
            logger.info(f"NEW HEADER DETECTED - Changed LOB from '{old_lob}' to '{self.current_lob}'")
        
        # 3. Sub-header-level: Update when new section appears
        for section in extraction.sections:
            if section.place_of_service_found:
                # Validate it's a real section header, not a column name
                valid_sections = ["INPATIENT RATES", "OUTPATIENT RATES", "INPATIENT CARVE OUT RATES", "OUTPATIENT CARVE OUT RATES"]
                if any(valid in section.place_of_service_found.upper() for valid in valid_sections):
                    old_pos = self.current_place_of_service
                    self.current_place_of_service = section.place_of_service_found
                    logger.info(f"NEW SECTION DETECTED - Changed place of service from '{old_pos}' to '{self.current_place_of_service}'")
                else:
                    logger.warning(f"INVALID place_of_service ignored: '{section.place_of_service_found}' (not a valid section header)")
                
            if section.plan_type_found:
                old_plan = self.current_plan_type
                self.current_plan_type = section.plan_type_found
                logger.info(f"NEW SECTION - Changed plan type from '{old_plan}' to '{self.current_plan_type}'")
    
    def write_rows(self, extraction: PageExtraction) -> int:
        """Write extracted rows processing each section individually"""
        if not self.csv_writer:
            return 0
        
        rows_written = 0
        
        # Process each section separately
        for section_num, section in enumerate(extraction.sections, 1):
            logger.info(f"Processing section {section_num} on this page")
            
            # Update place of service for this section
            section_place_of_service = self.current_place_of_service  # Default to current
            section_plan_type = self.current_plan_type  # Default to current
            
            # Check if this section has new place of service
            if section.place_of_service_found:
                valid_sections = ["INPATIENT RATES", "OUTPATIENT RATES", "INPATIENT CARVE OUT RATES", "OUTPATIENT CARVE OUT RATES"]
                if any(valid in section.place_of_service_found.upper() for valid in valid_sections):
                    # Update the state for this and subsequent sections
                    old_pos = self.current_place_of_service
                    self.current_place_of_service = section.place_of_service_found
                    section_place_of_service = self.current_place_of_service
                    logger.info(f"Section {section_num}: Changed place of service from '{old_pos}' to '{self.current_place_of_service}'")
                else:
                    logger.warning(f"Section {section_num}: Invalid place_of_service ignored: '{section.place_of_service_found}'")
            
            # Check if this section has new plan type
            if section.plan_type_found:
                old_plan = self.current_plan_type
                self.current_plan_type = section.plan_type_found
                section_plan_type = self.current_plan_type
                logger.info(f"Section {section_num}: Changed plan type from '{old_plan}' to '{self.current_plan_type}'")
            
            # Write all rows for this section
            section_rows = 0
            for row in section.table_rows:
                csv_row = [
                    self.system_name,                    # Stored once for PDF
                    self.effective_date,                 # Stored once for PDF
                    self.current_hospitals,              # Sticky until new header
                    self.current_lob,                   # Sticky until new header
                    section_place_of_service,           # Current section's place of service
                    section_plan_type,                  # Current section's plan type
                    row.service,                        # From current row
                    row.billing_codes,                  # From current row
                    row.rate                            # From current row
                ]
                self.csv_writer.writerow(csv_row)
                section_rows += 1
                rows_written += 1
            
            logger.info(f"Section {section_num}: Wrote {section_rows} rows with place_of_service='{section_place_of_service}'")
        
        if self.csv_file:
            self.csv_file.flush()
        
        logger.info(f"Total rows written from this page: {rows_written}")
        return rows_written
    
    def get_current_state(self):
        """Get current state for debugging"""
        return {
            'system_name': self.system_name,
            'effective_date': self.effective_date,
            'hospitals': self.current_hospitals,
            'lob': self.current_lob,
            'place_of_service': self.current_place_of_service,
            'plan_type': self.current_plan_type
        }
    
    def close_csv(self):
        """Close CSV file"""
        if self.csv_file:
            self.csv_file.close()
            self.csv_file = None
            self.csv_writer = None

class PDFExtractor:
    """PDF extractor using hierarchical store-and-reuse approach"""
    
    def __init__(self, client, output_dir: str = "extraction_output"):
        self.client = client
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.state_manager = HierarchicalStateManager()
    
    def get_extraction_prompt(self) -> str:
        """Generate extraction prompt based on real PDF examples"""
        json_schema = json.dumps(PageExtraction.model_json_schema(), indent=2)
        
        return f"""
You are an expert data extraction specialist. Extract data from this hospital rate schedule page using a hierarchical approach.

**EXTRACTION STRATEGY - Top to Bottom:**

**1. Document-Level Info (extract only if visible on THIS page):**
- system_name_found: Look at the very top corner for system names like "Mercy Health", "Memorial Health System", "Advocate Health And Hospital Corporation"
- effective_date_found: Look for "Effective Date:" followed by a date like "09/01/2024", "06/01/2025"

**2. Header-Level Info (SCAN EVERY PAGE FOR HOSPITAL NAMES):**
- hospital_names_found: SCAN THE ENTIRE PAGE for hospital/medical facility names. Finding these names is the most important step for context.
  * Look in page headers, footers, main document titles, and any prominent text boxes.
  * Hospital names must be COMPLETE facility names, not just the word "Hospital"
  * Valid examples: "Mercy Springfield and Urbana Hospitals", "Mercy Health Youngstown Hospital", "Sistersville General Hospital"
  * INVALID examples: Just "Hospital" by itself - this is NOT a hospital name
  * Extract the complete facility name (without TIN numbers).
  * ONLY extract when you find a COMPLETE hospital name - NEVER extract just "Hospital"
  * DO NOT extract if you only see the word "Hospital" without the facility name
- line_of_business_found: Look for the overall business line. This describes the general insurance category.
  * Words like: "Commercial", "Medicare", "Medicaid", "Health Plan", "Qualified"
  * Often appears near hospital names in headers.
  * Extract the complete business line description.

**3. Table Sections (extract when NEW section headers appear):**
For each section, look for:
- place_of_service_found: NEW section titles like:
  * "INPATIENT RATES"
  * "OUTPATIENT RATES"
  * "INPATIENT CARVE OUT RATES"
  * "OUTPATIENT CARVE OUT RATES"
  Extract only if this is a NEW section header.
- plan_type_found: Sub-headers under place_of_service that specify a plan variation.
  * Look for keywords like: "PPO", "HMO", "EPO", "POS", "Point of Service", "Exclusive Provider Organization".
  * Extract only if found under a NEW section header.
- table_rows: Extract data from any content organized into clear columns and rows, even if visual borders or lines are faint or missing. Look for repeating row structures under headers like "Service", "Billing Codes", and "Rates".
  * DO NOT extract from paragraphs or unstructured lists. The data must be in a grid-like or columnar format.
  * For each valid table row extract:
    * service: Full service description.
    * billing_codes: Complete billing codes.
    * rate: Complete rate text.

**CRITICAL RULES:**
- A document title like "Rate Schedule" or "Hospital Rates" is NOT a line_of_business_found. A Line of Business describes the general insurance category (e.g., Commercial, Medicare).
- Plan Types (PPO, HMO, etc.) are found *within* a Place of Service section and should be extracted as plan_type_found.
- SCAN EVERY PAGE for COMPLETE hospital names, NOT just the word "Hospital" by itself.
- DO NOT extract hospital_names_found if you only see "Hospital" without the facility name.
- ONLY extract hospital_names_found when you see COMPLETE facility names like "Mercy Springfield and Urbana Hospitals".
- Remove TIN numbers but keep the hospital name.
- EVERY COMPLETE hospital name must be extracted - NO EXCEPTIONS
- If you only see "Hospital" in a table cell, DO NOT extract it as hospital_names_found
- Preserve ALL text in table rows exactly as written.

**JSON Schema:**
{json_schema}
"""
    
    def process_page(self, image_path: Path, page_num: int) -> Tuple[int, bool]:
        """Process single page with systematic methodology and debugging"""
        logger.info(f"=== PROCESSING PAGE {page_num}: {image_path.name} ===")
        
        # Show current state before processing
        current_state = self.state_manager.get_current_state()
        logger.info(f"Current state before processing: {current_state}")
        
        try:
            with open(image_path, 'rb') as f:
                image_bytes = f.read()
            
            mime_type = 'image/png' if image_path.suffix.lower() == '.png' else 'image/jpeg'
            prompt = self.get_extraction_prompt()
            
            logger.info("Sending extraction request to AI...")
            
            # API call with fallback
            try:
                response = self.client.models.generate_content(
                    model='gemini-2.0-flash',
                    contents=[
                        types.Part.from_bytes(data=image_bytes, mime_type=mime_type),
                        prompt
                    ]
                )
            except (AttributeError, TypeError):
                response = self.client.generate_content(
                    contents=[
                        types.Part.from_bytes(data=image_bytes, mime_type=mime_type),
                        prompt
                    ]
                )
            
            logger.info("Received response from AI, parsing...")
            
            # Clean response
            response_text = response.text.strip()
            if response_text.startswith('```json'):
                response_text = response_text.split('```json')[1]
            if response_text.endswith('```'):
                response_text = response_text.rsplit('```', 1)[0]
            response_text = response_text.strip()
            
            # Debug: Log raw response
            logger.info(f"Cleaned AI response: {response_text[:500]}...")
            
            # Parse and validate
            extraction = PageExtraction.model_validate_json(response_text)
            
            # Debug: Log what was extracted
            logger.info(f"Extracted fields:")
            logger.info(f"  - system_name_found: {extraction.system_name_found}")
            logger.info(f"  - effective_date_found: {extraction.effective_date_found}")
            logger.info(f"  - hospital_names_found: {extraction.hospital_names_found}")
            logger.info(f"  - line_of_business_found: {extraction.line_of_business_found}")
            logger.info(f"  - sections found: {len(extraction.sections)}")
            
            # Update hierarchical state
            self.state_manager.update_from_page(extraction)
            
            # Write rows using stored context
            rows_written = self.state_manager.write_rows(extraction)
            
            # Show updated state after processing
            updated_state = self.state_manager.get_current_state()
            logger.info(f"Updated state after processing: {updated_state}")
            logger.info(f"Page {page_num}: {rows_written} rows extracted")
            
            # Validation checks
            if extraction.hospital_names_found:
                logger.info(f"✅ SUCCESS: Hospital name extracted on page {page_num}")
            else:
                logger.warning(f"⚠️  WARNING: No hospital name extracted on page {page_num}")
                
            if extraction.sections:
                logger.info(f"✅ SUCCESS: {len(extraction.sections)} sections found on page {page_num}")
            else:
                logger.warning(f"⚠️  WARNING: No sections found on page {page_num}")
            
            return rows_written, True
            
        except Exception as e:
            logger.error(f"❌ CRITICAL ERROR on page {page_num}: {e}")
            logger.error(f"Exception type: {type(e).__name__}")
            import traceback
            logger.error(f"Full traceback: {traceback.format_exc()}")
            return 0, False
    
    def extract_from_pdf(self, pdf_path: str, dpi: int = 200) -> Dict:
        """Extract data from single PDF using store-and-reuse approach"""
        pdf_path = Path(pdf_path)
        logger.info(f"Starting hierarchical extraction: {pdf_path.name}")
        
        try:
            # Reset state for new PDF
            self.state_manager.reset_document_state()
            
            # Convert to images
            image_output_dir = self.output_dir / pdf_path.stem / "images"
            image_paths = pdf_to_images(str(pdf_path), str(image_output_dir), dpi)
            
            # Setup CSV
            csv_path = self.output_dir / pdf_path.stem / f"{pdf_path.stem}_extracted.csv"
            csv_path.parent.mkdir(parents=True, exist_ok=True)
            self.state_manager.start_csv(csv_path)
            
            # Process pages sequentially (top to bottom)
            total_rows = 0
            successful_pages = 0
            
            logger.info("Processing pages sequentially (top to bottom)...")
            
            for i, image_path in enumerate(image_paths, 1):
                logger.info(f"\n--- PAGE {i} ---")
                rows, success = self.process_page(image_path, i)
                total_rows += rows
                if success:
                    successful_pages += 1
            
            # Final state
            final_state = self.state_manager.get_current_state()
            
            results = {
                'pdf_name': pdf_path.name,
                'total_pages': len(image_paths),
                'successful_pages': successful_pages,
                'total_rows': total_rows,
                'csv_path': str(csv_path),
                'final_state': final_state,
                'success_rate': f"{successful_pages}/{len(image_paths)}"
            }
            
            logger.info(f"\nExtraction complete: {pdf_path.name}")
            logger.info(f"Final state: {final_state}")
            logger.info(f"Pages: {successful_pages}/{len(image_paths)} successful")
            logger.info(f"Total rows: {total_rows}")
            logger.info(f"CSV saved: {csv_path}")
            
            return results
            
        except Exception as e:
            logger.error(f"Failed to extract {pdf_path.name}: {e}")
            raise
            
        finally:
            self.state_manager.close_csv()

def create_client():
    """Create client with your setup"""
    try:
        client = genai.Client(vertexai=True, project="anbc-hcb-dev", location="us-central1")
        logger.info("Created Vertex AI client")
        return client
    except Exception as e:
        logger.error(f"Failed to create client: {e}")
        raise

if __name__ == "__main__":
    # Test single PDF with hierarchical approach
    pdf_file = r"path/to/your/test.pdf"  # Change this to your test PDF
    
    try:
        # Create client
        client = create_client()
        
        # Create extractor
        extractor = PDFExtractor(client=client, output_dir="hierarchical_extraction")
        
        # Extract using store-and-reuse approach
        results = extractor.extract_from_pdf(pdf_file, dpi=200)
        
        # Print results
        print("\n" + "="*60)
        print("HIERARCHICAL EXTRACTION RESULTS")
        print("="*60)
        print(f"PDF: {results['pdf_name']}")
        print(f"Pages processed: {results['success_rate']}")
        print(f"Total rows: {results['total_rows']}")
        print(f"Final state: {results['final_state']}")
        print(f"CSV output: {results['csv_path']}")
        print("="*60)
        
    except Exception as e:
        logger.critical(f"Extraction failed: {e}")
        print(f"Error: {e}")
        print("Check hospital_extraction.log for details")
