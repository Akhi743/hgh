import fitz
import os
import csv
import json
import logging
from pathlib import Path
from typing import List, Optional, Dict, Tuple
from pydantic import BaseModel, Field
from google.genai import types
import google.genai as genai

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('hospital_extraction.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class TableRow(BaseModel):
    service: str = Field(description="The full service description from the row.")
    billing_codes: str = Field(description="The full, verbatim text of all billing codes in the cell.")
    rate: str = Field(description="The full, verbatim text of the rate, including all conditions.")

class Section(BaseModel):
    place_of_service: str = Field(description="The title of this section (e.g., 'INPATIENT RATES', 'OUTPATIENT CARVE OUT RATES').")
    plan_type: Optional[str] = Field(default="N/A", description="The plan type associated with this section. Defaults to 'N/A' if not present.")
    table_rows: List[TableRow] = Field(description="A list of all table rows extracted from this specific section.")

class PageExtraction(BaseModel):
    system_name: Optional[str] = Field(default=None, description="The main system name for the entire document.")
    effective_date: Optional[str] = Field(default=None, description="The effective date for the document.")
    hospital_names: Optional[str] = Field(default=None, description="The specific hospital names mentioned in the page header.")
    line_of_business: Optional[str] = Field(default=None, description="The Line of Business mentioned in the page header.")
    sections: List[Section] = Field(description="A list of all data sections found on this page.")

def pdf_to_images(pdf_path: str, output_dir: str = None, dpi: int = 200) -> List[Path]:
    """Convert PDF pages to images"""
    pdf_path = Path(pdf_path)
    if not pdf_path.exists():
        raise FileNotFoundError(f"PDF file not found: {pdf_path}")
    
    if output_dir is None:
        output_dir = pdf_path.parent / f"{pdf_path.stem}_images"
    else:
        output_dir = Path(output_dir)
    
    output_dir.mkdir(parents=True, exist_ok=True)
    image_paths = []
    
    try:
        doc = fitz.open(str(pdf_path))
        logger.info(f"Converting PDF '{pdf_path.name}' ({len(doc)} pages)")
        
        for page_num in range(len(doc)):
            page = doc.load_page(page_num)
            mat = fitz.Matrix(dpi / 72, dpi / 72)
            pix = page.get_pixmap(matrix=mat)
            
            output_path = output_dir / f"{pdf_path.stem}_page_{page_num + 1:03d}.png"
            pix.save(str(output_path))
            image_paths.append(output_path)
            
        doc.close()
        logger.info(f"Successfully converted {len(image_paths)} pages")
        
    except Exception as e:
        logger.error(f"Failed to convert PDF '{pdf_path.name}': {e}")
        raise
    
    return image_paths

class StateManager:
    """Manages sticky context across pages and writes to CSV"""
    
    def __init__(self):
        self.columns = [
            "System name", "Effective date", "Hospital Name/Names", 
            "Line of Business", "Place of service", "Plan type", 
            "Service", "Billing codes", "Rate"
        ]
        self.reset_state()
    
    def reset_state(self):
        """Reset state for new document"""
        self.current_system_name = "N/A"
        self.current_effective_date = "N/A"
        self.current_hospitals = "N/A"
        self.current_lob = "N/A"
        self.csv_file = None
        self.csv_writer = None
        self.csv_path = None
    
    def start_csv(self, output_path: Path):
        """Start new CSV file"""
        self.csv_path = output_path
        self.csv_file = open(self.csv_path, 'w', newline='', encoding='utf-8')
        self.csv_writer = csv.writer(self.csv_file)
        self.csv_writer.writerow(self.columns)
        logger.info(f"Started CSV: {self.csv_path}")
    
    def update_state(self, extraction: PageExtraction):
        """Update sticky context"""
        if extraction.system_name:
            self.current_system_name = extraction.system_name
        if extraction.effective_date:
            self.current_effective_date = extraction.effective_date
        if extraction.hospital_names:
            self.current_hospitals = extraction.hospital_names
        if extraction.line_of_business:
            self.current_lob = extraction.line_of_business
    
    def write_rows(self, extraction: PageExtraction) -> int:
        """Write extracted rows to CSV"""
        if not self.csv_writer:
            return 0
        
        rows_written = 0
        for section in extraction.sections:
            for row in section.table_rows:
                csv_row = [
                    self.current_system_name,
                    self.current_effective_date,
                    self.current_hospitals,
                    self.current_lob,
                    section.place_of_service,
                    section.plan_type,
                    row.service,
                    row.billing_codes,
                    row.rate
                ]
                self.csv_writer.writerow(csv_row)
                rows_written += 1
        
        if self.csv_file:
            self.csv_file.flush()
        
        return rows_written
    
    def close_csv(self):
        """Close CSV file"""
        if self.csv_file:
            self.csv_file.close()
            self.csv_file = None
            self.csv_writer = None

class PDFExtractor:
    """PDF extractor for testing single PDFs"""
    
    def __init__(self, client, output_dir: str = "extraction_output"):
        self.client = client
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.state_manager = StateManager()
    
    def get_extraction_prompt(self) -> str:
        """Generate extraction prompt following the 4-part hierarchy"""
        json_schema = json.dumps(PageExtraction.model_json_schema(), indent=2)
        
        return f"""
You are an expert data extraction specialist. Analyze this hospital rate schedule page and extract data following this exact hierarchy:

**Part 1: Document-Level Context**
- system_name: Main system name (e.g., "Memorial Health System") 
- effective_date: Document effective date

**Part 2: Header-Level Context (Sticky)**
- hospital_names: Specific hospital names (not system names)
- line_of_business: LOB from headers (e.g., "Commercial Gatekeeper", "Qualified Health Plan Rates")

**Part 3: Sub-Header-Level Context (Sticky)**
- place_of_service: Service location (e.g., "INPATIENT RATES", "OUTPATIENT CARVE OUT RATES")  
- plan_type: Plan type if present, otherwise "N/A"

**Part 4: Row-Level Extraction**
For each table row, extract verbatim text for:
- service: Full service description
- billing_codes: Complete billing codes text  
- rate: Complete rate text with all conditions

**EXTRACTION RULES:**
- Only return values if visible on THIS page
- Extract ALL table rows found
- Preserve exact text - do not modify or parse
- Use "N/A" when values are not present
- Return valid JSON only

**JSON Schema:**
{json_schema}
"""
    
    def process_page(self, image_path: Path, page_num: int) -> Tuple[int, bool]:
        """Process single page"""
        logger.info(f"Processing page {page_num}: {image_path.name}")
        
        try:
            with open(image_path, 'rb') as f:
                image_bytes = f.read()
            
            mime_type = 'image/png' if image_path.suffix.lower() == '.png' else 'image/jpeg'
            prompt = self.get_extraction_prompt()
            
            # Try different API call patterns for compatibility
            try:
                # Vertex AI style
                response = self.client.models.generate_content(
                    model='gemini-2.0-flash',
                    contents=[
                        types.Part.from_bytes(data=image_bytes, mime_type=mime_type),
                        prompt
                    ]
                )
            except (AttributeError, TypeError):
                # Standard client style
                response = self.client.generate_content(
                    contents=[
                        types.Part.from_bytes(data=image_bytes, mime_type=mime_type),
                        prompt
                    ]
                )
            
            # Clean response text
            response_text = response.text.strip()
            if response_text.startswith('```json'):
                response_text = response_text.split('```json')[1]
            if response_text.endswith('```'):
                response_text = response_text.rsplit('```', 1)[0]
            response_text = response_text.strip()
            
            # Parse and process
            extraction = PageExtraction.model_validate_json(response_text)
            self.state_manager.update_state(extraction)
            rows_written = self.state_manager.write_rows(extraction)
            
            logger.info(f"Page {page_num}: {rows_written} rows extracted")
            return rows_written, True
            
        except Exception as e:
            logger.error(f"Failed to process page {page_num}: {e}")
            return 0, False
    
    def extract_from_pdf(self, pdf_path: str, dpi: int = 200) -> Dict:
        """Extract data from single PDF - main testing function"""
        pdf_path = Path(pdf_path)
        logger.info(f"Starting extraction: {pdf_path.name}")
        
        try:
            # Reset state for new PDF
            self.state_manager.reset_state()
            
            # Convert to images
            image_output_dir = self.output_dir / pdf_path.stem / "images"
            image_paths = pdf_to_images(str(pdf_path), str(image_output_dir), dpi)
            
            # Setup CSV
            csv_path = self.output_dir / pdf_path.stem / f"{pdf_path.stem}_extracted.csv"
            csv_path.parent.mkdir(parents=True, exist_ok=True)
            self.state_manager.start_csv(csv_path)
            
            # Process each page
            total_rows = 0
            successful_pages = 0
            
            for i, image_path in enumerate(image_paths, 1):
                rows, success = self.process_page(image_path, i)
                total_rows += rows
                if success:
                    successful_pages += 1
            
            # Results
            results = {
                'pdf_name': pdf_path.name,
                'total_pages': len(image_paths),
                'successful_pages': successful_pages,
                'total_rows': total_rows,
                'csv_path': str(csv_path),
                'success_rate': f"{successful_pages}/{len(image_paths)}"
            }
            
            logger.info(f"Extraction complete: {pdf_path.name}")
            logger.info(f"Pages: {successful_pages}/{len(image_paths)} successful")
            logger.info(f"Rows extracted: {total_rows}")
            logger.info(f"CSV saved: {csv_path}")
            
            return results
            
        except Exception as e:
            logger.error(f"Failed to extract {pdf_path.name}: {e}")
            raise
            
        finally:
            self.state_manager.close_csv()

def create_client():
    """Create client with your setup"""
    try:
        # Using your Vertex AI setup
        client = genai.Client(vertexai=True, project="anbc-hcb-dev", location="us-central1")
        logger.info("Created Vertex AI client")
        return client
    except Exception as e:
        logger.error(f"Failed to create client: {e}")
        raise

if __name__ == "__main__":
    # Test single PDF
    pdf_file = r"path/to/your/test.pdf"  # Change this to your test PDF
    
    try:
        # Create client
        client = create_client()
        
        # Create extractor
        extractor = PDFExtractor(client=client, output_dir="test_extraction")
        
        # Extract from single PDF
        results = extractor.extract_from_pdf(pdf_file, dpi=200)
        
        # Print results
        print("\n" + "="*50)
        print("EXTRACTION RESULTS")
        print("="*50)
        print(f"PDF: {results['pdf_name']}")
        print(f"Pages processed: {results['success_rate']}")
        print(f"Total rows: {results['total_rows']}")
        print(f"CSV output: {results['csv_path']}")
        print("="*50)
        
    except Exception as e:
        logger.critical(f"Extraction failed: {e}")
        print(f"Error: {e}")
        print("Check hospital_extraction.log for details")
