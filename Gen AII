import fitz  # PyMuPDF
import os
import csv
import json
import uuid
from pathlib import Path
from typing import List, Optional, Union, Dict, Any
from google.genai import types
import google.genai as genai
from langchain.prompts import PromptTemplate
from langchain.schema import HumanMessage
from langchain.output_parsers import PydanticOutputParser, OutputFixingParser
from langchain_core.exceptions import OutputParserException
from pydantic import BaseModel, Field
import pandas as pd

def pdf_to_images(pdf_path, output_dir=None, dpi=150, image_format='png'):
    """
    Convert each page of a PDF to individual images.
    """
    pdf_path = Path(pdf_path)
    
    if not pdf_path.exists():
        raise FileNotFoundError(f"PDF file not found: {pdf_path}")
    
    if output_dir is None:
        output_dir = pdf_path.parent
    else:
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)
    
    doc = fitz.open(pdf_path)
    image_paths = []
    
    for page_num in range(len(doc)):
        page = doc.load_page(page_num)
        
        # Create transformation matrix for DPI
        mat = fitz.Matrix(dpi/72, dpi/72)
        pix = page.get_pixmap(matrix=mat)
        
        # Generate output filename
        output_filename = f"{pdf_path.stem}_page_{page_num + 1:03d}.{image_format}"
        output_path = output_dir / output_filename
        
        # Save image
        pix.save(str(output_path))
        image_paths.append(str(output_path))
        
        print(f"Saved page {page_num + 1} to {output_path}")
        if page_num == 30:  # Increased limit
            print("Limiting to first 30 pages for large PDFs")
            break
    
    doc.close()
    return image_paths

class SimpleTableData(BaseModel):
    """
    Simplified model for table data extraction.
    """
    has_table: bool = Field(description="Whether a table is present")
    is_new_table: bool = Field(default=False, description="Is this a new table with headers?")
    is_continuation: bool = Field(default=False, description="Is this continuing a previous table?")
    
    # Document metadata
    hospital_name: Optional[str] = Field(default=None, description="Hospital/facility name found anywhere on page")
    effective_date: Optional[str] = Field(default=None, description="Effective date if found")
    service_type: Optional[str] = Field(default=None, description="INPATIENT or OUTPATIENT")
    lob_type: Optional[str] = Field(default=None, description="Line of business type")
    
    # Table structure
    column_headers: Optional[List[str]] = Field(default=None, description="Column headers if new table")
    
    # Simple data extraction - just rows as lists of strings
    data_rows: Optional[List[List[str]]] = Field(default=None, description="Rows as lists of strings in column order")
    
    # Partial row handling
    incomplete_top_row: Optional[List[str]] = Field(default=None, description="Incomplete row at top")
    incomplete_bottom_row: Optional[List[str]] = Field(default=None, description="Incomplete row at bottom")

class ImprovedTableRegistry:
    """
    Simplified registry that focuses on data integrity.
    """
    def __init__(self, output_dir: Path):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # Track tables
        self.tables = {}
        self.current_table_id = None
        
        # Document-level metadata (carry forward across pages)
        self.doc_hospital_name = None
        self.doc_service_type = None
        self.doc_effective_date = None
        self.doc_lob_type = None
        
        # Standard output format
        self.standard_headers = [
            'Hospital', 'LOB', 'Place_of_Service', 'Service_Category', 
            'Billing_Codes', 'Rate', 'Negotiated_Type', 'Effective_Date'
        ]
    
    def update_document_metadata(self, hospital_name=None, service_type=None, 
                                effective_date=None, lob_type=None):
        """Update document-level metadata if new values found."""
        
        if hospital_name and not self.doc_hospital_name:
            # Clean up hospital name - remove system prefixes and focus on facility name
            cleaned_name = self._clean_hospital_name(hospital_name)
            if cleaned_name:
                self.doc_hospital_name = cleaned_name
                print(f"Set document hospital: {cleaned_name}")
        
        if service_type and not self.doc_service_type:
            self.doc_service_type = service_type
            print(f"Set document service type: {service_type}")
            
        if effective_date and not self.doc_effective_date:
            self.doc_effective_date = effective_date
            print(f"Set document effective date: {effective_date}")
            
        if lob_type and not self.doc_lob_type:
            self.doc_lob_type = lob_type
            print(f"Set document LOB: {lob_type}")
    
    def _clean_hospital_name(self, raw_name: str) -> str:
        """Extract actual hospital name from raw text."""
        if not raw_name:
            return None
            
        # Handle multiple hospitals - take the first one
        if "," in raw_name:
            raw_name = raw_name.split(",")[0].strip()
        
        # Remove common system prefixes but keep facility names
        system_prefixes = [
            "mercy health", "memorial health system", "advocate health",
            "advocate health and hospital corporation"
        ]
        
        name_lower = raw_name.lower()
        
        # Check if this is just a system name (no facility identifier)
        facility_indicators = [
            "hospital", "medical center", "medical centre", "clinic", 
            "health center", "health centre", "general", "regional",
            "community", "university", "children's", "specialty"
        ]
        
        has_facility_indicator = any(indicator in name_lower for indicator in facility_indicators)
        
        if has_facility_indicator:
            # This looks like a real facility name
            return raw_name.strip()
        else:
            # This might just be a system name, skip it
            return None
    
    def create_new_table(self, table_data: SimpleTableData, page_num: int) -> str:
        """Create a new table."""
        table_id = str(uuid.uuid4())[:8]
        
        # Update metadata
        self.update_document_metadata(
            table_data.hospital_name,
            table_data.service_type,
            table_data.effective_date,
            table_data.lob_type
        )
        
        # Create CSV file
        csv_filename = f"hospital_rates_{table_id}.csv"
        csv_path = self.output_dir / csv_filename
        
        # Store table info
        self.tables[table_id] = {
            'csv_path': str(csv_path),
            'start_page': page_num,
            'last_page': page_num,
            'original_headers': table_data.column_headers or [],
            'pending_partial': None
        }
        
        # Create CSV with standard headers
        with open(csv_path, 'w', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            writer.writerow(self.standard_headers)
        
        self.current_table_id = table_id
        print(f"Created new table: {csv_filename}")
        return table_id
    
    def add_rows_to_table(self, table_id: str, rows: List[List[str]], 
                         page_num: int, incomplete_top=None, incomplete_bottom=None):
        """Add rows to existing table with partial row handling."""
        if table_id not in self.tables:
            print(f"Warning: Table {table_id} not found")
            return
        
        table_info = self.tables[table_id]
        table_info['last_page'] = page_num
        
        # Handle partial row from previous page
        final_rows = []
        
        if table_info.get('pending_partial') and incomplete_top:
            # Merge partial rows
            merged_row = self._merge_partial_rows(table_info['pending_partial'], incomplete_top)
            if merged_row:
                final_rows.append(merged_row)
                print(f"Merged partial row from pages {page_num-1} and {page_num}")
        elif table_info.get('pending_partial'):
            # Add the orphaned partial row
            final_rows.append(table_info['pending_partial'])
        
        # Add regular rows
        if rows:
            final_rows.extend(rows)
        
        # Store new partial row for next page
        table_info['pending_partial'] = incomplete_bottom
        
        # Convert to standard format and write to CSV
        if final_rows:
            standardized_rows = self._convert_to_standard_format(final_rows)
            self._append_to_csv(table_info['csv_path'], standardized_rows)
            print(f"Added {len(final_rows)} rows to table {table_id}")
    
    def _merge_partial_rows(self, bottom_row: List[str], top_row: List[str]) -> List[str]:
        """Merge two partial rows intelligently."""
        merged = []
        max_len = max(len(bottom_row), len(top_row))
        
        for i in range(max_len):
            bottom_val = bottom_row[i] if i < len(bottom_row) else ""
            top_val = top_row[i] if i < len(top_row) else ""
            
            # Use the non-empty value, or combine if both exist
            if bottom_val and top_val:
                # For billing codes, concatenate
                if i == 1:  # Assuming billing codes are column 1
                    merged.append(f"{bottom_val}, {top_val}")
                else:
                    # Use the longer/more complete value
                    merged.append(bottom_val if len(bottom_val) > len(top_val) else top_val)
            else:
                merged.append(bottom_val or top_val)
        
        return merged
    
    def _convert_to_standard_format(self, rows: List[List[str]]) -> List[Dict[str, str]]:
        """Convert raw rows to standardized format."""
        standardized = []
        
        for row in rows:
            if not any(cell.strip() for cell in row):  # Skip empty rows
                continue
            
            # Ensure we have enough columns
            while len(row) < 4:
                row.append("")
            
            # Determine place of service
            service_type = self.doc_service_type or "INPATIENT"
            place_of_service = "OP" if "OUTPATIENT" in service_type.upper() else "IP"
            
            standardized_row = {
                'Hospital': self.doc_hospital_name or "Unknown",
                'LOB': self.doc_lob_type or "Commercial",
                'Place_of_Service': place_of_service,
                'Service_Category': row[0] if len(row) > 0 else "",
                'Billing_Codes': row[1] if len(row) > 1 else "",
                'Rate': row[2] if len(row) > 2 else "",
                'Negotiated_Type': row[3] if len(row) > 3 else "",
                'Effective_Date': self.doc_effective_date or ""
            }
            standardized.append(standardized_row)
        
        return standardized
    
    def _append_to_csv(self, csv_path: str, rows: List[Dict[str, str]]):
        """Append rows to CSV file."""
        with open(csv_path, 'a', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            for row in rows:
                writer.writerow([row.get(header, "") for header in self.standard_headers])
    
    def finalize_tables(self):
        """Finalize any pending partial rows."""
        for table_id, table_info in self.tables.items():
            if table_info.get('pending_partial'):
                print(f"Finalizing partial row for table {table_id}")
                standardized = self._convert_to_standard_format([table_info['pending_partial']])
                self._append_to_csv(table_info['csv_path'], standardized)
                table_info['pending_partial'] = None

class ImprovedTableExtractor:
    """
    Simplified, more robust table extractor.
    """
    
    def __init__(self, client, output_dir: str = None):
        self.client = client
        self.output_dir = Path(output_dir) if output_dir else Path.cwd()
        self.registry = ImprovedTableRegistry(self.output_dir)
    
    def create_extraction_prompt(self) -> tuple:
        """Create a simplified, focused extraction prompt."""
        base_parser = PydanticOutputParser(pydantic_object=SimpleTableData)
        
        class GeminiLLM:
            def __init__(self, client):
                self.client = client
            
            def __call__(self, prompt: str) -> str:
                try:
                    response = self.client.models.generate_content(
                        model='gemini-2.0-flash',
                        contents=[prompt]
                    )
                    return response.text
                except Exception as e:
                    return f"Error: {e}"
        
        llm_wrapper = GeminiLLM(self.client)
        parser = OutputFixingParser.from_llm(parser=base_parser, llm=llm_wrapper)
        
        template = """
You are a data extraction expert for hospital rate schedules. 

STEP 1 - FIND METADATA AT BEGINNING OF TABLES:
- Hospital name: Look in the headers/title area RIGHT ABOVE the table for specific hospital names:
  * Examples: "Sistersville General Hospital", "Advocate Christ Medical Center"
  * May be listed in document headers or right before table sections
  * Multiple hospitals may be listed (e.g., "ADVOCATE CHRIST MEDICAL CENTER, ADVOCATE GOOD SAMARITAN HOSPITAL")
  * If multiple hospitals, extract the first one or most prominent one
- LOB (Line of Business): Look for these terms in headers/titles before tables:
  * "COMMERCIAL", "MEDICARE", "MEDICAID" 
  * "GATEKEEPER", "NON-GATEKEEPER"
  * "Qualified Health Plan"
- Service type: Look for section headers:
  * "INPATIENT RATES:" or "OUTPATIENT RATES:"
  * "INPATIENT CARVE OUT RATES:"
- Effective date: Look for "Effective Date:" with a date, often in headers

FOCUS: Look at the text immediately above and around the table structure, not scattered throughout the page.

STEP 2 - DETECT TABLE TYPE:
- NEW TABLE: Has column headers like "Service", "Billing Codes", "Rates"  
- CONTINUATION: Just data rows, no headers (continuing from previous page)
- NO TABLE: No structured data present

STEP 3 - EXTRACT DATA (if table present):
For table data, extract each row as a simple list of strings in column order:
- Column 0: Service/procedure name
- Column 1: All billing codes (exactly as shown)
- Column 2: Rate amount only (no extra text)
- Column 3: Rate type/description

STEP 4 - HANDLE PARTIAL ROWS:
- incomplete_top_row: If first row seems cut off from previous page
- incomplete_bottom_row: If last row seems to continue on next page

IMPORTANT RULES:
1. Extract text EXACTLY as shown - don't modify or interpret
2. Keep billing codes complete with all numbers/letters  
3. For rates, extract just the number/percentage/amount
4. Mark rows as incomplete only if clearly cut off

{format_instructions}

Analyze this image carefully:
"""
        
        prompt = PromptTemplate(
            template=template,
            input_variables=[],
            partial_variables={"format_instructions": parser.get_format_instructions()}
        )
        
        return prompt, parser
    
    def process_page(self, image_path: str, page_num: int) -> Dict[str, Any]:
        """Process a single page."""
        print(f"\nProcessing page {page_num}: {Path(image_path).name}")
        
        try:
            with open(image_path, 'rb') as f:
                image_bytes = f.read()
            
            mime_type = 'image/png' if image_path.lower().endswith('.png') else 'image/jpeg'
            
            # Extract data using simplified prompt
            prompt, parser = self.create_extraction_prompt()
            prompt_text = prompt.format()
            
            response = self.client.models.generate_content(
                model='gemini-2.0-flash',
                contents=[
                    types.Part.from_bytes(data=image_bytes, mime_type=mime_type),
                    prompt_text
                ]
            )
            
            parsed_data = parser.parse(response.text.strip())
            
            # Update document metadata
            self.registry.update_document_metadata(
                parsed_data.hospital_name,
                parsed_data.service_type,
                parsed_data.effective_date,
                parsed_data.lob_type
            )
            
            if not parsed_data.has_table:
                return {
                    'page_num': page_num,
                    'has_table': False,
                    'status': 'No table found'
                }
            
            # Handle table data
            if parsed_data.is_new_table:
                # Start new table
                table_id = self.registry.create_new_table(parsed_data, page_num)
                
                # Add data if present
                if parsed_data.data_rows:
                    self.registry.add_rows_to_table(
                        table_id, 
                        parsed_data.data_rows, 
                        page_num,
                        parsed_data.incomplete_top_row,
                        parsed_data.incomplete_bottom_row
                    )
                
                return {
                    'page_num': page_num,
                    'has_table': True,
                    'table_type': 'new',
                    'table_id': table_id,
                    'rows_added': len(parsed_data.data_rows or [])
                }
            
            elif parsed_data.is_continuation or self.registry.current_table_id:
                # Continue existing table
                table_id = self.registry.current_table_id
                
                if table_id:
                    self.registry.add_rows_to_table(
                        table_id,
                        parsed_data.data_rows or [],
                        page_num,
                        parsed_data.incomplete_top_row,
                        parsed_data.incomplete_bottom_row
                    )
                    
                    return {
                        'page_num': page_num,
                        'has_table': True,
                        'table_type': 'continuation',
                        'table_id': table_id,
                        'rows_added': len(parsed_data.data_rows or [])
                    }
            
            return {
                'page_num': page_num,
                'has_table': False,
                'status': 'Table detected but could not process'
            }
            
        except Exception as e:
            print(f"Error processing page {page_num}: {e}")
            return {
                'page_num': page_num,
                'has_table': False,
                'error': str(e)
            }
    
    def extract_tables_from_pdf(self, pdf_path: str, dpi: int = 200, image_format: str = 'png') -> Dict[str, Any]:
        """
        Extract all tables from PDF.
        """
        print(f"Starting extraction for: {pdf_path}")
        
        # Convert PDF to images
        image_paths = pdf_to_images(pdf_path, self.output_dir, dpi, image_format)
        
        # Process each page
        results = {
            'pdf_path': pdf_path,
            'total_pages': len(image_paths),
            'processed_pages': [],
            'tables_created': [],
            'total_rows_extracted': 0
        }
        
        for page_num, image_path in enumerate(image_paths, 1):
            page_result = self.process_page(image_path, page_num)
            results['processed_pages'].append(page_result)
            
            if page_result.get('rows_added'):
                results['total_rows_extracted'] += page_result['rows_added']
        
        # Finalize any pending data
        self.registry.finalize_tables()
        
        # Collect final results
        for table_id, table_info in self.registry.tables.items():
            results['tables_created'].append({
                'table_id': table_id,
                'csv_path': table_info['csv_path'],
                'pages': f"{table_info['start_page']}-{table_info['last_page']}"
            })
        
        # Summary
        print(f"\n=== EXTRACTION COMPLETE ===")
        print(f"Total pages: {results['total_pages']}")
        print(f"Tables created: {len(results['tables_created'])}")
        print(f"Total rows extracted: {results['total_rows_extracted']}")
        print(f"Document metadata:")
        print(f"  Hospital: {self.registry.doc_hospital_name}")
        print(f"  Service Type: {self.registry.doc_service_type}")
        print(f"  Effective Date: {self.registry.doc_effective_date}")
        print(f"  LOB: {self.registry.doc_lob_type}")
        
        if results['tables_created']:
            print(f"\nCSV files created:")
            for table in results['tables_created']:
                print(f"  - {table['csv_path']}")
        
        return results

# Usage example
if __name__ == "__main__":
    # Example usage
    pdf_file = r"C:\Users\N873855\Documents\extracted_tables\Mercy_health.pdf"
    
    from google import genai
    client = genai.Client(vertexai=True, project="anbc-hcb-dev", location="us-central1")
    
    extractor = ImprovedTableExtractor(client, output_dir="extracted_tables")
    results = extractor.extract_tables_from_pdf(pdf_file, dpi=200)
    
    print("\\nExtraction complete! Check the CSV files for results.")
