import fitz
import os
import csv
import json
import logging
from pathlib import Path
from typing import List, Optional, Dict
from pydantic import BaseModel, Field
from google.genai import types
import google.genai as genai

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('hospital_extraction.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class TableRow(BaseModel):
    service: str = Field(description="The service description")
    billing_codes: Optional[str] = Field(description="Billing codes (empty string if none)")
    rate: Optional[str] = Field(description="Rate information (empty string if none)")

class PageExtraction(BaseModel):
    # Document-level metadata (extracted once per document)
    system_name: Optional[str] = Field(default=None, description="Health system name from top corner")
    effective_date: Optional[str] = Field(default=None, description="Effective date from document")
    
    # Section-level metadata (changes with new sections)
    hospital_names: Optional[str] = Field(default=None, description="Hospital names from main title")
    line_of_business: Optional[str] = Field(default=None, description="LOB from main title area")
    place_of_service: Optional[str] = Field(default=None, description="INPATIENT/OUTPATIENT section header")
    
    # Table data
    table_rows: List[TableRow] = Field(description="All table rows from this page")
    
    # Page classification
    is_new_section: bool = Field(default=False, description="Whether this starts a new section")
    is_continuation: bool = Field(default=False, description="Whether this continues previous table")

def pdf_to_images(pdf_path: str, output_dir: str = None, dpi: int = 200) -> List[Path]:
    """Convert PDF pages to images"""
    pdf_path = Path(pdf_path)
    if not pdf_path.exists():
        raise FileNotFoundError(f"PDF file not found: {pdf_path}")
    
    if output_dir is None:
        output_dir = pdf_path.parent / f"{pdf_path.stem}_images"
    else:
        output_dir = Path(output_dir)
    
    output_dir.mkdir(parents=True, exist_ok=True)
    image_paths = []
    
    try:
        doc = fitz.open(str(pdf_path))
        logger.info(f"Converting PDF '{pdf_path.name}' ({len(doc)} pages)")
        
        for page_num in range(len(doc)):
            page = doc.load_page(page_num)
            mat = fitz.Matrix(dpi / 72, dpi / 72)
            pix = page.get_pixmap(matrix=mat)
            
            output_path = output_dir / f"{pdf_path.stem}_page_{page_num + 1:03d}.png"
            pix.save(str(output_path))
            image_paths.append(output_path)
            
        doc.close()
        logger.info(f"Successfully converted {len(image_paths)} pages")
        
    except Exception as e:
        logger.error(f"Failed to convert PDF '{pdf_path.name}': {e}")
        raise
    
    return image_paths

class DocumentStateManager:
    """Manages hierarchical document state with proper inheritance"""
    
    def __init__(self):
        self.standard_columns = [
            "System Name", "Effective Date", "Hospital Names", 
            "Line of Business", "Place of Service", 
            "Service", "Billing Codes", "Rate"
        ]
        self.reset_state()
    
    def reset_state(self):
        """Reset all state for new document"""
        # Document-level (set once, never changes)
        self.system_name = None
        self.effective_date = None
        
        # Section-level (changes with new major sections)
        self.current_hospitals = None
        self.current_lob = None
        
        # Sub-section level (changes with place of service)
        self.current_place_of_service = None
        
        # CSV management
        self.csv_file = None
        self.csv_writer = None
        self.csv_path = None
        
        logger.info("Reset document state")
    
    def start_csv(self, output_path: Path):
        """Initialize CSV file with headers"""
        self.csv_path = output_path
        self.csv_file = open(self.csv_path, 'w', newline='', encoding='utf-8')
        self.csv_writer = csv.writer(self.csv_file)
        self.csv_writer.writerow(self.standard_columns)
        logger.info(f"Started CSV: {self.csv_path}")
    
    def update_state(self, extraction: PageExtraction, page_num: int):
        """Update state based on page extraction"""
        
        # Document-level: Set once and keep
        if extraction.system_name and not self.system_name:
            self.system_name = extraction.system_name
            logger.info(f"Page {page_num}: Set system name = '{self.system_name}'")
            
        if extraction.effective_date and not self.effective_date:
            self.effective_date = extraction.effective_date
            logger.info(f"Page {page_num}: Set effective date = '{self.effective_date}'")
        
        # Section-level: Update when new section detected
        if extraction.hospital_names:
            self.current_hospitals = extraction.hospital_names
            logger.info(f"Page {page_num}: Updated hospitals = '{self.current_hospitals}'")
            
        if extraction.line_of_business:
            self.current_lob = extraction.line_of_business
            logger.info(f"Page {page_num}: Updated LOB = '{self.current_lob}'")
        
        # Sub-section level: Update place of service
        if extraction.place_of_service:
            # Validate it's a real section header
            valid_sections = ["INPATIENT", "OUTPATIENT", "CARVE OUT"]
            if any(section in extraction.place_of_service.upper() for section in valid_sections):
                self.current_place_of_service = extraction.place_of_service
                logger.info(f"Page {page_num}: Updated place of service = '{self.current_place_of_service}'")
    
    def write_rows(self, extraction: PageExtraction, page_num: int) -> int:
        """Write extracted rows to CSV"""
        if not self.csv_writer:
            return 0
        
        rows_written = 0
        
        for row in extraction.table_rows:
            csv_row = [
                self.system_name or "N/A",
                self.effective_date or "N/A", 
                self.current_hospitals or "N/A",
                self.current_lob or "N/A",
                self.current_place_of_service or "N/A",
                row.service or "",
                row.billing_codes or "",
                row.rate or ""
            ]
            self.csv_writer.writerow(csv_row)
            rows_written += 1
        
        if self.csv_file:
            self.csv_file.flush()
        
        logger.info(f"Page {page_num}: Wrote {rows_written} rows")
        return rows_written
    
    def get_current_state(self):
        """Get current state for debugging"""
        return {
            'system_name': self.system_name,
            'effective_date': self.effective_date,
            'hospitals': self.current_hospitals,
            'lob': self.current_lob,
            'place_of_service': self.current_place_of_service
        }
    
    def close_csv(self):
        """Close CSV file"""
        if self.csv_file:
            self.csv_file.close()
            self.csv_file = None
            self.csv_writer = None

class HospitalRateExtractor:
    """Main extractor class for hospital rate schedules"""
    
    def __init__(self, client, output_dir: str = "extraction_output"):
        self.client = client
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.state_manager = DocumentStateManager()
    
    def create_extraction_prompt(self) -> str:
        """Create extraction prompt for hospital rate documents"""
        schema = json.dumps(PageExtraction.model_json_schema(), indent=2)
        
        return f"""
You are an expert at extracting data from hospital rate schedule documents. 

EXTRACTION RULES:

1. **Document-Level Information** (extract only if visible on THIS page):
   - system_name: Health system name from top corner (e.g., "Mercy Health", "Memorial Health System")
   - effective_date: Date from "Effective Date:" label (usually top-right)

2. **Section-Level Information** (extract only if visible on THIS page):
   - hospital_names: Specific hospital names from main title area
     * Extract actual hospital names like "Mercy Springfield and Urbana Hospitals" 
     * NOT system names like "Mercy Health"
     * Look for names near the center of the page in large text
   - line_of_business: LOB from main title area
     * Examples: "COMMERCIAL GATEKEEPER AND NON-GATEKEEPER PRODUCTS"
     * "Qualified Health Plan rates", "MEDICARE", "MEDICAID"
     * Extract exactly as written, don't substitute

3. **Sub-Section Information**:
   - place_of_service: Section headers like:
     * "INPATIENT RATES"
     * "OUTPATIENT RATES" 
     * "INPATIENT CARVE OUT RATES"
     * "OUTPATIENT CARVE OUT RATES"

4. **Table Data Extraction**:
   - table_rows: Extract from structured tables with columns
   - For each row extract:
     * service: Full service description
     * billing_codes: All billing codes (use "" if empty)
     * rate: Complete rate text (use "" if empty)

5. **Important Rules**:
   - Only extract fields that are clearly visible on THIS page
   - Use null for fields not found on current page
   - For empty table cells, use empty string "" not null
   - Extract hospital names from the main title area, not system names
   - Extract LOB from same area as hospital names

JSON Schema:
{schema}

Analyze this hospital rate schedule page and extract the information:
"""
    
    def process_page(self, image_path: Path, page_num: int) -> tuple[int, bool]:
        """Process a single page"""
        logger.info(f"Processing page {page_num}: {image_path.name}")
        
        try:
            with open(image_path, 'rb') as f:
                image_bytes = f.read()
            
            mime_type = 'image/png' if image_path.suffix.lower() == '.png' else 'image/jpeg'
            prompt = self.create_extraction_prompt()
            
            # Make API call
            response = self.client.models.generate_content(
                model='gemini-2.0-flash',
                contents=[
                    types.Part.from_bytes(data=image_bytes, mime_type=mime_type),
                    prompt
                ]
            )
            
            # Clean and parse response
            response_text = response.text.strip()
            if response_text.startswith('```json'):
                response_text = response_text.split('```json')[1]
            if response_text.endswith('```'):
                response_text = response_text.rsplit('```', 1)[0]
            response_text = response_text.strip()
            
            # Parse extraction
            extraction = PageExtraction.model_validate_json(response_text)
            
            # Update state based on extraction
            self.state_manager.update_state(extraction, page_num)
            
            # Write rows to CSV
            rows_written = self.state_manager.write_rows(extraction, page_num)
            
            # Log what was found
            current_state = self.state_manager.get_current_state()
            logger.info(f"Page {page_num} - Current state: {current_state}")
            logger.info(f"Page {page_num} - Rows extracted: {rows_written}")
            
            return rows_written, True
            
        except Exception as e:
            logger.error(f"Error processing page {page_num}: {e}")
            return 0, False
    
    def extract_from_pdf(self, pdf_path: str, dpi: int = 200) -> Dict:
        """Extract data from entire PDF"""
        pdf_path = Path(pdf_path)
        logger.info(f"Starting extraction: {pdf_path.name}")
        
        try:
            # Reset state for new PDF
            self.state_manager.reset_state()
            
            # Convert PDF to images
            image_output_dir = self.output_dir / pdf_path.stem / "images"
            image_paths = pdf_to_images(str(pdf_path), str(image_output_dir), dpi)
            
            # Setup CSV output
            csv_path = self.output_dir / pdf_path.stem / f"{pdf_path.stem}_extracted.csv"
            csv_path.parent.mkdir(parents=True, exist_ok=True)
            self.state_manager.start_csv(csv_path)
            
            # Process each page
            total_rows = 0
            successful_pages = 0
            
            for i, image_path in enumerate(image_paths, 1):
                rows, success = self.process_page(image_path, i)
                total_rows += rows
                if success:
                    successful_pages += 1
            
            # Final results
            final_state = self.state_manager.get_current_state()
            
            results = {
                'pdf_name': pdf_path.name,
                'total_pages': len(image_paths),
                'successful_pages': successful_pages,
                'total_rows': total_rows,
                'csv_path': str(csv_path),
                'final_state': final_state,
                'success_rate': f"{successful_pages}/{len(image_paths)}"
            }
            
            logger.info(f"Extraction complete for {pdf_path.name}")
            logger.info(f"Final state: {final_state}")
            logger.info(f"Success rate: {results['success_rate']}")
            logger.info(f"Total rows: {total_rows}")
            logger.info(f"CSV saved: {csv_path}")
            
            return results
            
        except Exception as e:
            logger.error(f"Failed to extract {pdf_path.name}: {e}")
            raise
            
        finally:
            self.state_manager.close_csv()

def create_client():
    """Create Gemini client"""
    try:
        client = genai.Client(vertexai=True, project="anbc-hcb-dev", location="us-central1")
        logger.info("Created Vertex AI client")
        return client
    except Exception as e:
        logger.error(f"Failed to create client: {e}")
        raise

if __name__ == "__main__":
    # Example usage
    pdf_file = r"path/to/your/test.pdf"  # Change this path
    
    try:
        # Create client and extractor
        client = create_client()
        extractor = HospitalRateExtractor(client=client, output_dir="hospital_extraction")
        
        # Extract data
        results = extractor.extract_from_pdf(pdf_file, dpi=200)
        
        # Print summary
        print("\n" + "="*50)
        print("EXTRACTION RESULTS")
        print("="*50)
        print(f"PDF: {results['pdf_name']}")
        print(f"Pages: {results['success_rate']}")
        print(f"Rows: {results['total_rows']}")
        print(f"CSV: {results['csv_path']}")
        print(f"State: {results['final_state']}")
        print("="*50)
        
    except Exception as e:
        logger.critical(f"Extraction failed: {e}")
        print(f"Error: {e}")
        print("Check hospital_extraction.log for details")
