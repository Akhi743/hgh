import fitz  # PyMuPDF
import os
import csv
import json
import logging
from pathlib import Path
from typing import List, Optional, Dict

# Pydantic is used for defining the data structure for the AI model's output
from pydantic import BaseModel, Field

# Using LangChain for parsing, as in your original script
from langchain.prompts import PromptTemplate
from langchain.output_parsers import PydanticOutputParser

# Using Google Cloud AI Platform, which we found works in your environment
from google.cloud import aiplatform
from google.cloud.aiplatform_v1.types.content import Part

# Configure logging to see the script's progress and catch any issues.
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('hospital_extraction.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# --- Data Models (Using our perfected, hierarchical models) ---

class TableRow(BaseModel):
    service: str = Field(description="The full service description from the row.")
    billing_codes: str = Field(description="The full, verbatim text of all billing codes in the cell.")
    rate: str = Field(description="The full, verbatim text of the rate, including all conditions.")

class Section(BaseModel):
    place_of_service: str = Field(description="The title of this section (e.g., 'INPATIENT RATES', 'OUTPATIENT CARVE OUT RATES').")
    plan_type: Optional[str] = Field(default="N/A", description="The plan type associated with this section (e.g., 'For POS...'). Defaults to 'N/A' if not present.")
    table_rows: List[TableRow] = Field(description="A list of all table rows extracted from this specific section.")

class PageExtraction(BaseModel):
    system_name: Optional[str] = Field(default=None, description="The top-level system name for the entire document. Provide only if visible on this page.")
    effective_date: Optional[str] = Field(default=None, description="The effective date for the document. Provide only if visible on this page.")
    hospital_names: Optional[str] = Field(default=None, description="The specific hospital names in the page header. Provide only if visible on this page.")
    line_of_business: Optional[str] = Field(default=None, description="The Line of Business in the page header. Provide only if visible on this page.")
    sections: List[Section] = Field(description="A list of all data sections found on this page, from top to bottom.")

# --- PDF and Image Conversion ---

def pdf_to_images(pdf_path: str, output_dir: Path, dpi: int = 200) -> List[Path]:
    pdf_path = Path(pdf_path)
    if not pdf_path.exists():
        logger.error(f"PDF file not found: {pdf_path}")
        raise FileNotFoundError(f"PDF file not found: {pdf_path}")
    output_dir.mkdir(parents=True, exist_ok=True)
    image_paths = []
    try:
        doc = fitz.open(pdf_path)
        logger.info(f"PDF '{pdf_path.name}' has {len(doc)} pages. Starting conversion...")
        for page_num in range(len(doc)):
            page = doc.load_page(page_num)
            mat = fitz.Matrix(dpi / 72, dpi / 72)
            pix = page.get_pixmap(matrix=mat)
            output_path = output_dir / f"{pdf_path.stem}_page_{page_num + 1:03d}.png"
            pix.save(str(output_path))
            image_paths.append(output_path)
        doc.close()
        logger.info(f"Successfully converted all {len(image_paths)} pages.")
    except Exception as e:
        logger.error(f"Failed to convert PDF '{pdf_path.name}': {e}")
        raise
    return image_paths

# --- State and CSV Management ---

class StateManager:
    def __init__(self):
        self.columns = ["System name", "Effective date", "Hospital Name/Names", "Line of Business", "Place of service", "Plan type", "Service", "Billing codes", "Rate"]
        self.reset_state()
    def reset_state(self):
        self.current_system_name, self.current_effective_date, self.current_hospitals, self.current_lob = "N/A", "N/A", "N/A", "N/A"
        self.csv_file, self.csv_writer, self.csv_path = None, None, None
    def start_csv(self, output_path: Path):
        self.reset_state()
        self.csv_path = output_path
        self.csv_file = open(self.csv_path, 'w', newline='', encoding='utf-8')
        self.csv_writer = csv.writer(self.csv_file)
        self.csv_writer.writerow(self.columns)
        logger.info(f"CSV file started: {self.csv_path}")
    def update_state(self, extraction: PageExtraction):
        if extraction.system_name: self.current_system_name = extraction.system_name
        if extraction.effective_date: self.current_effective_date = extraction.effective_date
        if extraction.hospital_names: self.current_hospitals = extraction.hospital_names
        if extraction.line_of_business: self.current_lob = extraction.line_of_business
    def write_rows(self, extraction: PageExtraction) -> int:
        rows_written = 0
        for section in extraction.sections:
            for row in section.table_rows:
                self.csv_writer.writerow([self.current_system_name, self.current_effective_date, self.current_hospitals, self.current_lob, section.place_of_service, section.plan_type, row.service, row.billing_codes, row.rate])
                rows_written += 1
        if self.csv_file: self.csv_file.flush()
        if rows_written > 0: logger.info(f"Wrote {rows_written} new rows to CSV.")
        else: logger.info("No table rows found in this page's extraction data.")
        return rows_written
    def close_csv(self):
        if self.csv_file:
            logger.info(f"CSV file closed: {self.csv_path}")
            self.csv_file.close()

# --- Extractor Class (Using your preferred 'SimpleExtractor' name and LangChain components) ---

class SimpleExtractor:
    def __init__(self, client, output_dir: str):
        self.client = client
        self.output_dir = Path(output_dir)
        self.state_manager = StateManager()

    def get_prompt_and_parser(self) -> tuple:
        """Creates the prompt and parser using LangChain, as in your original format."""
        
        parser = PydanticOutputParser(pydantic_object=PageExtraction)
        
        template = """You are an expert data extraction specialist. Your task is to analyze an image of a hospital rate schedule PDF page and convert it into a structured JSON object that matches the format instructions below.

Follow this precise hierarchical logic:

1.  **Extract Top-Level Context:** Look at the very top of the page for `system_name`, `effective_date`, `hospital_names`, and `line_of_business`. Only return values for these fields if they are explicitly visible on the CURRENT page.

2.  **Scan for Data Sections:** Work from top to bottom and identify every "Place of Service" section (e.g., "INPATIENT RATES").

3.  **Extract Section Data:** For each section, extract `place_of_service`, the `plan_type` (if any, else "N/A"), and all `table_rows`. For each row, extract the full, verbatim text for `service`, `billing_codes`, and `rate`.

{format_instructions}

Analyze the provided image and extract the data based on the rules above.
"""
        prompt = PromptTemplate(
            template=template,
            input_variables=[],
            partial_variables={"format_instructions": parser.get_format_instructions()}
        )
        return prompt, parser

    def process_page(self, image_path: Path, page_num: int) -> int:
        """Processes a single page image, extracts data, and writes to CSV."""
        logger.info(f"--- Processing page {page_num}: {image_path.name} ---")
        prompt_template, parser = self.get_prompt_and_parser()
        prompt_text = prompt_template.format()
        
        try:
            with open(image_path, 'rb') as f:
                image_bytes = f.read()

            image_part = Part(inline_data={'mime_type': 'image/png', 'data': image_bytes})
            prompt_part = Part(text=prompt_text)

            response = self.client.generate_content(contents=[image_part, prompt_part])
            
            # Use the LangChain parser to validate and structure the AI's response
            extraction = parser.parse(response.text)
            
            self.state_manager.update_state(extraction)
            rows_written = self.state_manager.write_rows(extraction)
            return rows_written
        except Exception as e:
            logger.error(f"CRITICAL FAILURE on page {page_num}. Error: {e}")
            return 0
        
    def extract_from_pdf(self, pdf_path: str, dpi: int = 200):
        """The main function to run the end-to-end extraction for a PDF."""
        logger.info(f"===== STARTING EXTRACTION FOR PDF: {pdf_path} =====")
        pdf_file = Path(pdf_path)
        run_output_dir = self.output_dir / pdf_file.stem
        try:
            image_paths = pdf_to_images(pdf_path, run_output_dir, dpi)
            csv_output_path = run_output_dir / f"{pdf_file.stem}_extracted_rates.csv"
            self.state_manager.start_csv(csv_output_path)
            total_rows_extracted = 0
            for i, image_path in enumerate(image_paths):
                rows_on_page = self.process_page(image_path, page_num=i + 1)
                total_rows_extracted += rows_on_page
            logger.info(f"===== EXTRACTION COMPLETE FOR: {pdf_path} =====")
        except Exception as e:
            logger.critical(f"A critical error stopped the extraction process for {pdf_path}: {e}")
        finally:
            self.state_manager.close_csv()

# --- Main Execution Block ---

if __name__ == "__main__":
    # 1. Set the path to your PDF file
    pdf_file = r"path/to/your/hospital_rates.pdf"

    try:
        # 2. Set up the connection to your Vertex AI project
        PROJECT_ID = "anbc-hcb-dev" # Using the project from your screenshots
        LOCATION = "us-central1"
        
        # This initializes the connection.
        aiplatform.init(project=PROJECT_ID, location=LOCATION)
        
        # This creates the AI model object using the aiplatform library.
        client = aiplatform.GenerativeModel("gemini-1.5-flash-001")
        
        # 3. Create the extractor (using your preferred name 'SimpleExtractor') and run the process
        extractor = SimpleExtractor(client=client, output_dir="extracted_rates")
        extractor.extract_from_pdf(pdf_file, dpi=200)

        print("Extraction complete!")
        
    except Exception as e:
        logger.critical(f"An error occurred: {e}")
