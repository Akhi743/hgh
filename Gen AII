import fitz  # PyMuPDF
import os
import csv
from pathlib import Path
from typing import List, Optional, Dict, Any
from google.genai import types
import google.genai as genai
from langchain.prompts import PromptTemplate
from langchain.output_parsers import PydanticOutputParser, OutputFixingParser
from pydantic import BaseModel, Field

def pdf_to_images(pdf_path, output_dir=None, dpi=300, image_format='png'):
    """Convert each page of a PDF to individual images."""
    pdf_path = Path(pdf_path)
    
    if not pdf_path.exists():
        raise FileNotFoundError(f"PDF file not found: {pdf_path}")
    
    if output_dir is None:
        output_dir = pdf_path.parent
    else:
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)
    
    doc = fitz.open(pdf_path)
    image_paths = []
    
    for page_num in range(len(doc)):
        page = doc.load_page(page_num)
        mat = fitz.Matrix(dpi/72, dpi/72)
        pix = page.get_pixmap(matrix=mat)
        
        output_filename = f"{pdf_path.stem}_page_{page_num + 1:03d}.{image_format}"
        output_path = output_dir / output_filename
        
        pix.save(str(output_path))
        image_paths.append(str(output_path))
        
        print(f"Saved page {page_num + 1} to {output_path}")
        if page_num == 50:
            print("Limiting to first 50 pages for large PDFs")
            break
    
    doc.close()
    return image_paths

class PageData(BaseModel):
    """Data structure for extracted page information."""
    has_new_main_header: bool = Field(description="Whether page has a new main document header")
    hospital_names: Optional[List[str]] = Field(default=None, description="Hospital names from main header")
    lob_type: Optional[str] = Field(default=None, description="Line of Business type from main header")
    effective_date: Optional[str] = Field(default=None, description="Effective date from top right corner")
    place_of_service: Optional[str] = Field(default=None, description="Current place of service section")
    table_rows: List[Dict[str, str]] = Field(description="Table rows with service, billing_codes, rates")

class DocumentContext:
    """Tracks current document state across pages."""
    def __init__(self):
        self.current_hospitals = []
        self.current_lob = None
        self.current_place_of_service = None
        self.effective_date = None
        
    def update_from_page(self, page_data: PageData):
        """Update context based on page data."""
        if page_data.has_new_main_header and page_data.hospital_names:
            self.current_hospitals = page_data.hospital_names
        if page_data.lob_type:
            self.current_lob = page_data.lob_type
        if page_data.place_of_service:
            self.current_place_of_service = page_data.place_of_service
        if page_data.effective_date:
            self.effective_date = page_data.effective_date

class HospitalRateExtractor:
    """Main extractor class for hospital rate schedules."""
    
    def __init__(self, client, output_dir: str = None):
        self.client = client
        self.output_dir = Path(output_dir) if output_dir else Path.cwd()
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.context = DocumentContext()
        
        # CSV setup
        self.csv_columns = [
            'Hospital_Names', 'LOB', 'Place_of_Service', 'Service_Category', 
            'Billing_Codes', 'Rates', 'Effective_Date'
        ]
        
        self.csv_path = self.output_dir / "hospital_rates_extracted.csv"
        with open(self.csv_path, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.writer(csvfile)
            writer.writerow(self.csv_columns)
    
    def create_extraction_prompt(self) -> tuple:
        """Create prompt for page data extraction."""
        base_parser = PydanticOutputParser(pydantic_object=PageData)
        
        class GeminiLLM:
            def __init__(self, client):
                self.client = client
                
            def __call__(self, prompt: str) -> str:
                try:
                    response = self.client.models.generate_content(
                        model='gemini-2.0-flash',
                        contents=[prompt]
                    )
                    return response.text
                except Exception as e:
                    return f"Error: {e}"
        
        llm_wrapper = GeminiLLM(self.client)
        parser = OutputFixingParser.from_llm(parser=base_parser, llm=llm_wrapper)
        
        template = """
You are an expert at extracting hospital rate schedule data. Follow these EXACT rules:

STEP 1 - CHECK FOR NEW MAIN HEADER:
Look for a large, centered document title that contains hospital names like:
- "Sistersville General Hospital"
- "Mercy Springfield and Urbana Hospitals"
- "Advocate Condell Medical Center and Advocate Sherman Hospital"

If you find this, set has_new_main_header: true and extract:
- hospital_names: ALL hospital names from this main title (as a list)
- lob_type: Look for LOB indicators like "COMMERCIAL", "MEDICARE", "MEDICAID"

STEP 2 - EXTRACT EFFECTIVE DATE ONLY:
Look at TOP RIGHT CORNER and ONLY extract the effective date
- IGNORE the system name (like "Mercy Health", "Memorial Health System")
- ONLY extract: "Effective Date: MM/DD/YYYY" or similar date format
- IGNORE everything else in the top right corner

STEP 3 - IDENTIFY PLACE OF SERVICE:
Look for section headers like:
- "INPATIENT RATES"
- "OUTPATIENT RATES" 
- "INPATIENT CARVE OUT RATES"
- "OUTPATIENT CARVE OUT RATES"

Extract as: "INPATIENT", "OUTPATIENT", "INPATIENT CARVE OUT", "OUTPATIENT CARVE OUT"

STEP 4 - EXTRACT TABLE DATA:
For each table row, extract exactly as shown:
- service: Service description
- billing_codes: Billing codes/ranges
- rates: Rate amounts and descriptions

CRITICAL RULES:
- Hospital names come ONLY from main document headers, NEVER from top right corner
- From top right corner, extract ONLY the effective date, ignore system names
- Extract text exactly as it appears
- If no new header/section found, set fields to null
- Extract ALL visible table rows

{format_instructions}

Extract data from this page:
"""
        
        prompt = PromptTemplate(
            template=template,
            input_variables=[],
            partial_variables={"format_instructions": parser.get_format_instructions()}
        )
        
        return prompt, parser
    
    def process_page(self, image_path: str, page_num: int) -> Dict[str, Any]:
        """Process a single page and extract data."""
        print(f"Processing page {page_num}: {Path(image_path).name}")
        
        try:
            with open(image_path, 'rb') as f:
                image_bytes = f.read()
            
            mime_type = 'image/png' if image_path.lower().endswith('.png') else 'image/jpeg'
            
            prompt, parser = self.create_extraction_prompt()
            prompt_text = prompt.format()
            
            response = self.client.models.generate_content(
                model='gemini-2.0-flash',
                contents=[
                    types.Part.from_bytes(data=image_bytes, mime_type=mime_type),
                    prompt_text
                ]
            )
            
            page_data = parser.parse(response.text.strip())
            
            # Update context with new information
            self.context.update_from_page(page_data)
            
            # Save table rows to CSV
            rows_saved = 0
            for row in page_data.table_rows:
                self.save_row_to_csv(row)
                rows_saved += 1
            
            # Log findings
            if page_data.has_new_main_header:
                print(f"  New main header found")
                print(f"  Hospitals: {page_data.hospital_names}")
                print(f"  LOB: {page_data.lob_type}")
            
            if page_data.place_of_service:
                print(f"  Place of Service: {page_data.place_of_service}")
            
            if page_data.effective_date:
                print(f"  Effective Date: {page_data.effective_date}")
            
            print(f"  Rows extracted: {rows_saved}")
            
            return {
                'page_num': page_num,
                'has_new_header': page_data.has_new_main_header,
                'rows_extracted': rows_saved,
                'current_context': {
                    'hospitals': self.context.current_hospitals,
                    'lob': self.context.current_lob,
                    'place_of_service': self.context.current_place_of_service,
                    'effective_date': self.context.effective_date
                }
            }
            
        except Exception as e:
            print(f"Error processing page {page_num}: {e}")
            return {
                'page_num': page_num,
                'error': str(e),
                'rows_extracted': 0
            }
    
    def save_row_to_csv(self, row_data: Dict[str, str]):
        """Save a single row to the CSV file."""
        csv_row = [
            '; '.join(self.context.current_hospitals) if self.context.current_hospitals else 'N/A',
            self.context.current_lob or 'N/A',
            self.context.current_place_of_service or 'N/A',
            row_data.get('service', 'N/A'),
            row_data.get('billing_codes', 'N/A'),
            row_data.get('rates', 'N/A'),
            self.context.effective_date or 'N/A'
        ]
        
        with open(self.csv_path, 'a', newline='', encoding='utf-8') as csvfile:
            writer = csv.writer(csvfile)
            writer.writerow(csv_row)
    
    def extract_from_pdf(self, pdf_path: str, dpi: int = 300) -> Dict[str, Any]:
        """Extract all data from PDF following the hierarchical structure."""
        print(f"Starting extraction for: {pdf_path}")
        
        image_paths = pdf_to_images(pdf_path, self.output_dir, dpi, 'png')
        
        results = {
            'pdf_path': pdf_path,
            'total_pages': len(image_paths),
            'pages_processed': [],
            'total_rows_extracted': 0,
            'csv_file': str(self.csv_path)
        }
        
        for page_num, image_path in enumerate(image_paths, 1):
            page_result = self.process_page(image_path, page_num)
            results['pages_processed'].append(page_result)
            results['total_rows_extracted'] += page_result.get('rows_extracted', 0)
        
        print(f"\n=== EXTRACTION COMPLETE ===")
        print(f"Total pages: {results['total_pages']}")
        print(f"Total rows extracted: {results['total_rows_extracted']}")
        print(f"Output CSV: {results['csv_file']}")
        
        return results

# Usage
if __name__ == "__main__":
    pdf_file = "path/to/your/hospital_rates.pdf"
    
    from google import genai
    client = genai.Client(vertexai=True, project="your-project", location="us-central1")
    
    extractor = HospitalRateExtractor(client, output_dir="extracted_data")
    results = extractor.extract_from_pdf(pdf_file)
