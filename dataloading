"""GANITE Codebase for LaLonde Dataset."""
# Necessary packages
import numpy as np
import pandas as pd
from scipy.special import expit
from sklearn.preprocessing import StandardScaler, MinMaxScaler

def data_loading_lalonde(train_rate = 0.8):
    """Load LaLonde data."""
    try:
        ori_data = pd.read_csv("Dataset/lalonde.csv")
        print("Available columns:", ori_data.columns.tolist())
    except:
        raise ValueError("Cannot find Dataset/lalonde.csv")
    
    # Create feature matrix
    feature_columns = ['age', 'educ', 'race', 'married', 'nodegree', 're74', 're75']
    data = ori_data[feature_columns].copy()
    
    # Create dummy variables for categorical variables
    data = pd.get_dummies(data, columns=['race'], prefix=['race'])
    
    # Define continuous and binary features
    continuous_features = ['age', 'educ', 're74', 're75']
    binary_features = ['married', 'nodegree'] + [col for col in data.columns if col.startswith('race_')]
    
    # Apply StandardScaler to continuous features
    std_scaler = StandardScaler()
    data[continuous_features] = std_scaler.fit_transform(data[continuous_features])
    
    # Convert to numpy array
    x = data.values
    no, dim = x.shape
    
    # Get treatment and outcome
    t = ori_data['treat'].values
    y = ori_data['re78'].values
    
    # Apply MinMaxScaler to outcomes
    minmax_scaler = MinMaxScaler(feature_range=(0, 1))
    y_scaled = minmax_scaler.fit_transform(y.reshape(-1, 1)).flatten()
    
    # Store original min and max for inverse transform
    y_min, y_max = np.min(y), np.max(y)
    
    # Create potential outcomes
    potential_y = np.zeros((no, 2))
    
    # Observed factuals
    treated_idx = t == 1
    control_idx = t == 0
    
    potential_y[treated_idx, 1] = y_scaled[treated_idx]
    potential_y[control_idx, 0] = y_scaled[control_idx]
    
    # Estimate counterfactuals (using scaled values)
    treated_mean = np.mean(y_scaled[treated_idx])
    control_mean = np.mean(y_scaled[control_idx])
    
    # For control units, estimate treated outcome
    effect_ratio = treated_mean / control_mean if control_mean != 0 else 1
    potential_y[control_idx, 1] = y_scaled[control_idx] * effect_ratio
    
    # For treated units, estimate control outcome
    inverse_ratio = control_mean / treated_mean if treated_mean != 0 else 1
    potential_y[treated_idx, 0] = y_scaled[treated_idx] * inverse_ratio
    
    # Ensure scaled values stay in [0,1] range
    potential_y = np.clip(potential_y, 0, 1)
    
    # Reshape treatment
    t = t.reshape(-1)
    
    # Train/test division
    idx = np.random.permutation(no)
    train_idx = idx[:int(train_rate * no)]
    test_idx = idx[int(train_rate * no):]
    
    train_x = x[train_idx, :]
    train_t = t[train_idx]
    train_y = y_scaled[train_idx]
    train_potential_y = potential_y[train_idx, :]
    
    test_x = x[test_idx, :]
    test_potential_y = potential_y[test_idx, :]
    
    # Print scaling info
    print(f"Original outcome range: [{y_min:.2f}, {y_max:.2f}]")
    print(f"Scaled outcome range: [{np.min(y_scaled):.6f}, {np.max(y_scaled):.6f}]")
    
    scaler_dict = {
        'y_scaler': minmax_scaler,
        'y_min': y_min,
        'y_max': y_max
    }
    
    return train_x, train_t, train_y, train_potential_y, test_x, test_potential_y, scaler_dict
